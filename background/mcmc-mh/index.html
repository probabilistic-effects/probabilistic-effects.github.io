<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<title>MCMC and MH - Probabilistic Effects.  λθ</title>
<meta name="generator" content="Hugo 0.78.2" />
<link href="https://probabilistic-effects.github.io//index.xml" rel="alternate" type="application/rss+xml">
<link rel="canonical" href="https://probabilistic-effects.github.io/background/mcmc-mh/">
<link rel="stylesheet" href="https://probabilistic-effects.github.io/css/theme.min.css">
<script src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>
<link rel="stylesheet" href="https://probabilistic-effects.github.io/css/chroma.min.css">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script>
<script src="https://probabilistic-effects.github.io/js/bundle.js"></script><style>
:root {}
</style>
<meta property="og:title" content="MCMC and MH" />
<meta property="og:description" content="Monte Carlo Monte Carlo methods, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results.
These methods vary, but tend to follow a particular pattern:
 Define a domain of possible inputs Generate inputs randomly from a probability distribution over the domain Perform a deterministic computation on the inputs Aggregate the results   Markov Chain Monte Carlo (MCMC) Markov Chain Monte Carlo (MCMC) methods are from a class of techniques known as approximate inference which are a range of algorithms for computing posteriors when the likelihood is intractable." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://probabilistic-effects.github.io/background/mcmc-mh/" />
<meta property="article:published_time" content="2020-11-13T13:58:28+00:00" />
<meta property="article:modified_time" content="2020-11-13T13:58:28+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="MCMC and MH"/>
<meta name="twitter:description" content="Monte Carlo Monte Carlo methods, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results.
These methods vary, but tend to follow a particular pattern:
 Define a domain of possible inputs Generate inputs randomly from a probability distribution over the domain Perform a deterministic computation on the inputs Aggregate the results   Markov Chain Monte Carlo (MCMC) Markov Chain Monte Carlo (MCMC) methods are from a class of techniques known as approximate inference which are a range of algorithms for computing posteriors when the likelihood is intractable."/>
<meta itemprop="name" content="MCMC and MH">
<meta itemprop="description" content="Monte Carlo Monte Carlo methods, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results.
These methods vary, but tend to follow a particular pattern:
 Define a domain of possible inputs Generate inputs randomly from a probability distribution over the domain Perform a deterministic computation on the inputs Aggregate the results   Markov Chain Monte Carlo (MCMC) Markov Chain Monte Carlo (MCMC) methods are from a class of techniques known as approximate inference which are a range of algorithms for computing posteriors when the likelihood is intractable.">
<meta itemprop="datePublished" content="2020-11-13T13:58:28+00:00" />
<meta itemprop="dateModified" content="2020-11-13T13:58:28+00:00" />
<meta itemprop="wordCount" content="545">



<meta itemprop="keywords" content="" />
</head>
<body><div class="container"><header>
<h1>Probabilistic Effects.  λθ</h1>
</header>

<div class="content-container">
<main><h1>MCMC and MH</h1>
<h3 id="monte-carlo">Monte Carlo</h3>
<p>Monte Carlo methods, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results.</p>
<p>These methods vary, but tend to follow a particular pattern:</p>
<ol>
<li>Define a domain of possible inputs</li>
<li>Generate inputs randomly from a probability distribution over the domain</li>
<li>Perform a deterministic computation on the inputs</li>
<li>Aggregate the results</li>
</ol>
<hr>
<h3 id="markov-chain-monte-carlo-mcmc">Markov Chain Monte Carlo (MCMC)</h3>
<p>Markov Chain Monte Carlo (MCMC) methods are from a class of techniques known as <strong>approximate inference</strong> which are a range of algorithms for computing posteriors when the likelihood is intractable.</p>
<p>MCMC comprises of a class of algorithms for sampling from a probability distribution, based on constructing a Markov Chain that has the desired distribution as its stationary distribution. A stationary distribution of a Markov Chain is a probability distribution that remains unchanged in the Markov Chain as time progresses. The state of the chain after a number of steps is then used as a sample of the desired distribution. The quality of the sample improves as a function of the number of steps.</p>
<p><em><strong>For example:</strong></em></p>
<p>Assume <strong>we want to sample from a Beta distribution</strong>. This is a difficult/intractable problem. MCMC methods provide us with algorithms that could create a Markov Chain which has the Beta distribution as its stationary distribution, given that we can sample from a uniform distribution.</p>
<p>If we start from a random state and traverse to the next state based on some algorithm repeatedly, we will end up creating a Markov Chain which has the Beta distribution as its stationary distribution. The states we are at after a long time can be then used as a sample from the Beta distribution.</p>
<p>One such MCMC algorithm is the <strong>Metropolis-Hastings Algorithm</strong>.</p>
<hr>
<h3 id="metropolis-hastings-algorithm">Metropolis-Hastings Algorithm</h3>
<p>Metropolis-Hastings is an algorithm from the MCMC class of algorithms, for obtaining a sequence of random samples from a probability distribution from which direct sampling is difficult; as more and more sample values are produced, the distribution of values more closely approximates the desired distribution. These sample values represent the parameters of the distribution we&rsquo;re approximating.</p>
<p><strong>Algorithm</strong></p>
<p>Our desired distribution we&rsquo;re trying to approximate is <strong>p(θ)</strong>. However, we only know this distribution up to some normalising constant - this is the function <strong>g(θ)</strong> which is proportional to <strong>p(θ)</strong>.</p>
<ol>
<li>
<p><strong>Initialisation</strong>:</p>
<ul>
<li>
<p>Choose an arbitrary initial sample value <strong>θ<!-- raw HTML omitted -->0<!-- raw HTML omitted --></strong> to be the first sample.</p>
</li>
<li>
<p>We then choose an arbitrary proposal distribution <strong>q</strong>, where <strong>q(θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted --> | θ<!-- raw HTML omitted -->t<!-- raw HTML omitted -->)</strong> suggests a candidate for the next sample value <strong>θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted --></strong> given the current sample value <strong>θ<!-- raw HTML omitted -->t<!-- raw HTML omitted --></strong>.</p>
</li>
</ul>
</li>
<li>
<p><strong>For each iteration <em>t</em></strong>:</p>
<ul>
<li>
<p><strong>Generate</strong> a candidate <strong>θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted --></strong> for the next sample by drawing from a proposal distribution <strong>q</strong> of <strong>θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted --></strong> given the current iteration value <strong>θ<!-- raw HTML omitted -->t<!-- raw HTML omitted --></strong>.</p>
<blockquote>
<p><strong>θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted --> ~ q(θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted --> | θ<!-- raw HTML omitted -->t<!-- raw HTML omitted -->)</strong></p>
</blockquote>
</li>
<li>
<p><strong>Calculate</strong> the <em>acceptance ratio</em> which will be used to decide whether to accept or reject the candidate <strong>θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted --></strong>. Because <strong>g</strong> is proportional the density of <strong>p</strong>, we have that:</p>
<blockquote>
<p><strong>α = g(θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted -->) ⁄ g(θ<!-- raw HTML omitted -->t<!-- raw HTML omitted -->) = p(θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted -->) ⁄ p(θ<!-- raw HTML omitted -->t<!-- raw HTML omitted -->)</strong></p>
</blockquote>
<p>or equivalently:</p>
<blockquote>
<p><strong>α = (p(θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted -->) * p(data | θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted -->)) ⁄ (p(θ<!-- raw HTML omitted -->t<!-- raw HTML omitted -->) * p(data | θ<!-- raw HTML omitted -->t<!-- raw HTML omitted -->))</strong></p>
</blockquote>
</li>
<li>
<p><strong>Accept or reject</strong>: We generate a uniform random number <strong>u ∈ [0,1]</strong>, and accept if <strong>α ≥ u</strong>, or reject if <strong>α &lt; u</strong>.</p>
<blockquote>
<p><strong>if α &lt; (u ∈ [0,1]) : Reject θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted --> and retain θ<!-- raw HTML omitted -->t<!-- raw HTML omitted --> as current θ</strong></p>
</blockquote>
<blockquote>
<p><strong>if α ≥ (u ∈ [0,1]) : Accept θ<!-- raw HTML omitted -->t+1<!-- raw HTML omitted --> as current θ</strong></p>
</blockquote>
</li>
</ul>
</li>
</ol>
<div class="edit-meta">
Last updated on 13 Nov 2020


<br>
Published on 13 Nov 2020
<br></div><nav class="pagination"><a class="nav nav-prev" href="https://probabilistic-effects.github.io/background/mtl/" title="MTL"><i class="fas fa-arrow-left" aria-hidden="true"></i> Prev - MTL</a>
<a class="nav nav-next" href="https://probabilistic-effects.github.io/background/markov-chain/" title="Markov Chains">Next - Markov Chains <i class="fas fa-arrow-right" aria-hidden="true"></i></a>
</nav><footer><p class="powered">Powered by <a href="https://gohugo.io">Hugo</a>. Theme by <a href="https://themes.gohugo.io/hugo-theme-techdoc/">TechDoc</a>. Designed by <a href="https://github.com/thingsym/hugo-theme-techdoc">Thingsym</a>.</p>
</footer>
</main>
<div class="sidebar">

<nav class="open-menu">
<ul>
<li class=""><a href="https://probabilistic-effects.github.io/">Home</a></li>

<li class=""><a href="https://probabilistic-effects.github.io/activity/">Activity</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/activity/inlining-monad-bayes/">Inlining Monad Bayes</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/papers/">Papers</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/papers/freer-monads/">Freer Monads, More Extensible Effects</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/papers/fusion-for-free/">Fusion for Free</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/research/">Research</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/research/research-journal/">Research Journal</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/approaches-for-monad-bayes/">Potential Approaches to Improving Monad Bayes</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/effects-for-less/">Effects for Less</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/literature-review/">Literature Review</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/parsley-case-study/">Case Study: Optimising Parsley</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/optimising-core/">Optimising Core</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/">Monad Bayes</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/inference-transformers/">Inference Transformers</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/pmmh-hmm/">Implementing HMM Simulation and Inference (using PMMH)</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/conditioning-scoring/">How Conditioning and Scoring Works</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/tooling/">Tooling</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/tooling/cabal/">Cabal Projects</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/">Benchmarking</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/benchmark-log/">Benchmark Log</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/benchmarking-profiling/">How to Benchmark and Profile</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/monad-bayes-components/">Relevant Components of Monad Bayes for Profiling</a></li>
</ul>
  
</li>

<li class="parent"><a href="https://probabilistic-effects.github.io/background/">Background</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/background/staging/">Staging</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/smc-pmmh/">SMC and PMMH</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/handrolling/">Handrolling Monad Transformer Stacks</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/mtl/">MTL</a></li>
<li class="active"><a href="https://probabilistic-effects.github.io/background/mcmc-mh/">MCMC and MH</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/markov-chain/">Markov Chains</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/hidden-markov-model/">Hidden Markov Model</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/delimited-continuations/">Delimited Continuations</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/haskell-core/">Haskell Core</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/inlining/">Inlining</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/specialisation/">Specialisation</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/continuations/">Continuations</a></li>
</ul>
  
</li>
</ul>
</nav>



<div class="sidebar-footer"></div>
</div>

</div><a href="#" id="backtothetop-fixed" class="backtothetop"
 data-backtothetop-duration="600"
 data-backtothetop-easing="easeOutQuart"
 data-backtothetop-fixed-fadeIn="1000"
 data-backtothetop-fixed-fadeOut="1000"
 data-backtothetop-fixed-bottom="10"
 data-backtothetop-fixed-right="20">
<span class="fa-layers fa-fw">
<i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i>
</span></a>
</div>
</body>
</html>
