<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Background on Probabilistic Effects.  λθ</title>
    <link>https://probabilistic-effects.github.io/background/</link>
    <description>Recent content in Background on Probabilistic Effects.  λθ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Nov 2020 13:42:14 +0000</lastBuildDate><atom:link href="https://probabilistic-effects.github.io/background/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Embedding DSLs</title>
      <link>https://probabilistic-effects.github.io/background/embedding/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/embedding/</guid>
      <description>Tagless Final Style 2. Interpreters for first-order languages 2.1 Initial and Final embeddings We start with a very simple language to be later extended, which has integer literals, negation, and addition. Our running example is the expression:
8 + (- (1 + 2)) The initial embedding of the language encodes the expressions of the language as the values of an algebraic data type.
data Exp = Lit Int | Neg Exp | Add Exp Exp Our running example is written as follows:</description>
    </item>
    
    <item>
      <title>Staging</title>
      <link>https://probabilistic-effects.github.io/background/staging/</link>
      <pubDate>Fri, 13 Nov 2020 13:59:01 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/staging/</guid>
      <description>Staging and metaprogramming are the same; Template Haskell is a metaprogramming library for Haskell. We have different stages of computation, so staging a program is making it so that it compiles different parts of the program at different stages to be used by other parts of a program at a later stage.
Building blocks of Template Haskell The core mechanisms of Template Haskell are:
 Evaluating Haskell meta-programs at compile-time and splicing in the generated object programs as regular Haskell code Representing Template Haskell object programs as algebraic data types The quotation monad Q  • Writing a meta-program</description>
    </item>
    
    <item>
      <title>SMC and PMMH</title>
      <link>https://probabilistic-effects.github.io/background/smc-pmmh/</link>
      <pubDate>Fri, 13 Nov 2020 13:58:54 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/smc-pmmh/</guid>
      <description>Particle Filter Sequential Monte Carlo (SMC) methods, also known as Particle Filters, are a set of simulation-based methods (to artificially generate data to test a hypothesis) which provide an approach to computing the posterior distribution. The objective is to compute the posterior distributions of the states of some hidden Markov Model process, where the system consists of both hidden and observable variables.
The observable variables (observation process) are related to the hidden variables (state process) by some functional form that is known.</description>
    </item>
    
    <item>
      <title>Handrolling Monad Transformer Stacks</title>
      <link>https://probabilistic-effects.github.io/background/handrolling/</link>
      <pubDate>Fri, 13 Nov 2020 13:58:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/handrolling/</guid>
      <description>Unrolling MTL stacks Stacked monad transformers do not inline well and the MTL library often requires an optimisation pass.
Unrolling means to flatten a stack of transformers into a single hand-unrolled monad.
For example, consider the following MTL monad stack.
-- RWS monad: A monad containing an environment of type r, output of type w, and updatable state of type s. type RWS r w s = RWST r w s Identity deriving (MonadState s, MonadWriter w, Monad) newtype DRM a = DRM { unDRM :: ErrorT Finish (RWS () DNA RNA) a } deriving (MonadState DNA, MonadWriter RNA, MonadError Finish, Monad) -- | Inductive case: This tells us that as we know there is a MonadState and MonadWriter instance -- somewhere in the stack (i.</description>
    </item>
    
    <item>
      <title>MTL</title>
      <link>https://probabilistic-effects.github.io/background/mtl/</link>
      <pubDate>Fri, 13 Nov 2020 13:58:35 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/mtl/</guid>
      <description>Ordinary monad transformers Using ordinary monad transformers, we would have to construct a transformer stack like the following example:
type Environment = [(String, Int)] type Counter = Int newtype M a = M (ReaderT Environment (StateT Counter IO) a) deriving (Functor, Applicative, Monad) -- This inverts into something like IO (State Counter (Reader Environment a)) In order to access the environment, we can use the ask operation from Control.Monad.Trans.Reader, but we have to wrap this up in the M newtype.</description>
    </item>
    
    <item>
      <title>MCMC and MH</title>
      <link>https://probabilistic-effects.github.io/background/mcmc-mh/</link>
      <pubDate>Fri, 13 Nov 2020 13:58:28 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/mcmc-mh/</guid>
      <description>Monte Carlo Monte Carlo methods, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results.
These methods vary, but tend to follow a particular pattern:
 Define a domain of possible inputs Generate inputs randomly from a probability distribution over the domain Perform a deterministic computation on the inputs Aggregate the results   Markov Chain Monte Carlo (MCMC) Markov Chain Monte Carlo (MCMC) methods are from a class of techniques known as approximate inference which are a range of algorithms for computing posteriors when the likelihood is intractable.</description>
    </item>
    
    <item>
      <title>Markov Chains</title>
      <link>https://probabilistic-effects.github.io/background/markov-chain/</link>
      <pubDate>Fri, 13 Nov 2020 13:58:20 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/markov-chain/</guid>
      <description>Markov Chain A Markov Chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.
A Markov chain is a model that tells us about the probabilities of sequences of random variables, states, each of which can take on values from some set.
Formally, a Markov chain is specified by the following components:</description>
    </item>
    
    <item>
      <title>Hidden Markov Model</title>
      <link>https://probabilistic-effects.github.io/background/hidden-markov-model/</link>
      <pubDate>Fri, 13 Nov 2020 13:58:10 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/hidden-markov-model/</guid>
      <description>HMM A Markov chain is useful when we need to compute a probability for a sequence of observable events. In many cases, the events we are interested in are hidden - meaning we don&amp;rsquo;t observe them directly.
HMM allows us to talk about both observed events and hidden events that we think of as causal factors in our probabilistic model.
A HMM is specified by the following components:
  A set of N states</description>
    </item>
    
    <item>
      <title>Delimited Continuations</title>
      <link>https://probabilistic-effects.github.io/background/delimited-continuations/</link>
      <pubDate>Fri, 13 Nov 2020 13:57:22 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/delimited-continuations/</guid>
      <description>Delimited Continuations A limiting factor for effect system performance is the need to implement delimited continuations outside of the runtime. Accordingly, this proposal presents a design for native delimited continuation primitive operations that can be used to efficiently capture the RTS (runtime system) stack. A guiding principle of the design is to be minimal. Rather than burden GHC with the full complexity of designing and implementing algebraic effects, this proposal provides a path for users to experiment with designs as ordinary Haskell libraries without sacrificing performance.</description>
    </item>
    
    <item>
      <title>Haskell Core</title>
      <link>https://probabilistic-effects.github.io/background/haskell-core/</link>
      <pubDate>Fri, 13 Nov 2020 13:49:05 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/haskell-core/</guid>
      <description>• Core Language
The definition of the core language of GHC is given below - all source programs are compiled into this core language. All optimisation passes are in terms of this core language rather than the source programs.
data Expr b = Var Id | Lit Literal | App (Expr b) (Arg b) | Lam b (Expr b) | Let (Bind b) (Expr b) | Case (Expr b) b Type [Alt b] | Cast (Expr b) Coercion | Tick (Tickish Id) (Expr b) | Type Type | Coercion Coercion type Arg b = Expr b type Alt b = (AltCon, [b], Expr b) data AltCon = DataAlt DataCon | LitAlt Literal | DEFAULT data Bind b = NonRec b (Expr b) | Rec [(b, (Expr b))] • Basic Optimisations on Core</description>
    </item>
    
    <item>
      <title>Inlining</title>
      <link>https://probabilistic-effects.github.io/background/inlining/</link>
      <pubDate>Fri, 13 Nov 2020 13:49:05 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/inlining/</guid>
      <description>The most critical optimisation for an automatic optimiser is inlining. Inlining is the enabling optimisation which replaces a function name by the definition of that function. After a function definition has been inlined, new optimisation opportunities are now evident to the optimiser such as the β-reduction and know-case elimination optimisations.
The difficulty with inlining is that on its own it is not a beneficial code transformation. Inlining a function which does not unlock any further optimisation possibilities is wasted work which increases code size.</description>
    </item>
    
    <item>
      <title>Specialisation</title>
      <link>https://probabilistic-effects.github.io/background/specialisation/</link>
      <pubDate>Fri, 13 Nov 2020 13:49:05 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/specialisation/</guid>
      <description>Type class constraints in Haskell are implemented via dictionary passing. A function accepting a type class constraint is passed a record which provides evidence for the constraint. Therefore despite the fact that all instances have been statically resolved before runtime, the dictionaries are still passed to functions which can incur significant overhead.
Since type classes are ubiquitous, getting rid of this overhead is critical for any high-performance Haskell programs. Therefore one of the most important optimisations in the compiler is specialisation which rewrites functions to remove the overhead of passing a statically known dictionary.</description>
    </item>
    
    <item>
      <title>Continuations</title>
      <link>https://probabilistic-effects.github.io/background/continuations/</link>
      <pubDate>Fri, 13 Nov 2020 13:40:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/continuations/</guid>
      <description>What are continuations? Continuations represent the future of a computation, as a function from an intermediate result to the final result. Direct-style functions are computations which return their result directly, with general type a -&amp;gt; b.
The direct-style factorial fac takes a single argument.
fac :: Integral a =&amp;gt; a -&amp;gt; a fac 0 = 1 fac n = n * fac (n - 1) Continuation-passing-style functions are suspended computations with general type a -&amp;gt; (b -&amp;gt; r) -&amp;gt; r, which represent direct-style functions with type a -&amp;gt; b.</description>
    </item>
    
    <item>
      <title>Coroutines</title>
      <link>https://probabilistic-effects.github.io/background/coroutines/</link>
      <pubDate>Fri, 13 Nov 2020 13:40:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/coroutines/</guid>
      <description>Coroutines are the act of cooperatively passing control around.
Monad-Coroutine Monads as Imperative Languages
Haskell provides do notation which is syntactic sugar to facilitate imperative programming. The monad of a do block specifies the imperative language which is typically equipped with actions. Monad transformers are then language enhancers. They add additional actions to an underlying language.
The Pause transformer
The Pause monad transformer will augment the underlying language with one additional action: pause.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://probabilistic-effects.github.io/background/monad-transformers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/monad-transformers/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
