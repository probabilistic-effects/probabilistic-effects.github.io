<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<title>Documentation - Probabilistic Effects.  λθ</title>
<meta name="generator" content="Hugo 0.80.0" />
<link href="https://probabilistic-effects.github.io//index.xml" rel="alternate" type="application/rss+xml">
<link rel="canonical" href="https://probabilistic-effects.github.io/monad-bayes/documentation/">
<link rel="stylesheet" href="https://probabilistic-effects.github.io/css/theme.min.css">
<script src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>
<link rel="stylesheet" href="https://probabilistic-effects.github.io/css/chroma.min.css">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script>
<script src="https://probabilistic-effects.github.io/js/bundle.js"></script><style>
:root {}
</style>
<meta property="og:title" content="Documentation" />
<meta property="og:description" content="1. What Does Monad-Bayes Do? The general way of inferring a posterior distribution given a likelihood and a prior is an approximate inference technique called MCMC which are a whole class of methods to infer the posterior. A key point to note is that although we are inferring the posterior, we are also inferring an estimate of the likelihood as well using the data. Inference in general is the act of predicting the values of something which we don&rsquo;t have access to directly, given some data." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://probabilistic-effects.github.io/monad-bayes/documentation/" />
<meta property="article:published_time" content="2020-11-13T14:04:44+00:00" />
<meta property="article:modified_time" content="2020-11-13T14:04:44+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Documentation"/>
<meta name="twitter:description" content="1. What Does Monad-Bayes Do? The general way of inferring a posterior distribution given a likelihood and a prior is an approximate inference technique called MCMC which are a whole class of methods to infer the posterior. A key point to note is that although we are inferring the posterior, we are also inferring an estimate of the likelihood as well using the data. Inference in general is the act of predicting the values of something which we don&rsquo;t have access to directly, given some data."/>
<meta itemprop="name" content="Documentation">
<meta itemprop="description" content="1. What Does Monad-Bayes Do? The general way of inferring a posterior distribution given a likelihood and a prior is an approximate inference technique called MCMC which are a whole class of methods to infer the posterior. A key point to note is that although we are inferring the posterior, we are also inferring an estimate of the likelihood as well using the data. Inference in general is the act of predicting the values of something which we don&rsquo;t have access to directly, given some data.">
<meta itemprop="datePublished" content="2020-11-13T14:04:44+00:00" />
<meta itemprop="dateModified" content="2020-11-13T14:04:44+00:00" />
<meta itemprop="wordCount" content="4536">



<meta itemprop="keywords" content="" />
</head>
<body><div class="container"><header>
<h1>Probabilistic Effects.  λθ</h1>
</header>

<div class="content-container">
<main><h1>Documentation</h1>
<h4 id="1-what-does-monad-bayes-do">1. What Does Monad-Bayes Do?</h4>
<p>The general way of inferring a posterior distribution given a likelihood and a prior is an approximate inference technique called MCMC which are a whole class of methods to infer the posterior. A key point to note is that although we are inferring the posterior, we are also inferring an estimate of the likelihood as well using the data. Inference in general is the act of predicting the values of something which we don&rsquo;t have access to directly, given some data. At the highest level, there is inference over the posterior distribution of the parameters.</p>
<p>Monad Bayes uses a particle filter to infer the likelihood of a given model, and uses metropolis-hastings (or more specifically, the trace metropolis-hastings algorithm) to infer the posterior distribution over any desired given quantity. (A particle filter is only needed when we do not have an exact formulation of the likelihood). Monad Bayes offers the user a very generic version of trace metropolis-hastings, and a particle filter &ndash; in general, these two components can be combined to produce different algorithms (such as PMMH or SMC). In theory, one could extend this implementation with one&rsquo;s own altered version of metropolis-hastings. Particle filters and metropolis-hastings are just two possible base building blocks of a lot of statistical algorithms. In general, the idea of the library monad-bayes is very vague &ndash; at its core, it is an effectful, type-class approach to probalistic programming. Whilst monad-bayes has implementations of trace metropolis-hastings and particle filters within it, these are just building blocks of other algorithms and it is possible to use monad-bayes in many ways.</p>
<h4 id="2-the-free-monad-transformer">2. The Free Monad Transformer</h4>
<h5 id="21-the-free-monad">2.1 The Free Monad</h5>
<p><code>FreeF</code> is the fixed point version of the free monad <code>Free</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#66d9ef">data</span> <span style="color:#66d9ef">FreeF</span> f a x <span style="color:#f92672">=</span> <span style="color:#66d9ef">Pure</span> a <span style="color:#f92672">|</span> <span style="color:#66d9ef">Free</span> (f x)
</code></pre></div><p>By wrapping a functor within the free monad, this allows us to treat the functor (or technically <code>Free f</code>) as a monad, i.e. an effectful computation. By constructing values of type <code>Free f</code>, we are simply constructing a data type in the form of a syntax tree. The important thing to note is that this tree on its own has no computation associated with it &ndash; it exists as a data type. How we evaluate a free monad tree is determined by what interpreter functions we choose to define. This means that we have decoupled the syntax of our program from its semantics.</p>
<p>When binding over a free monad, <code>(Free f a) -&gt; (a -&gt; Free f b) -&gt; Free f b</code>, this says: execute the effectful computation <code>Free f a</code>, extract the value <code>a</code> from this, and execute another effectful computation <code>Free f b</code>.</p>
<h5 id="22-the-free-monad-transformer">2.2 The Free Monad Transformer</h5>
<p>Using normal free monads, we can build abstract syntax trees which let us abstract away the interpreter, however, sometimes we can&rsquo;t specify the syntax tree all at once. Often we want to interleave the syntax tree with some other monad to generate streaming or interactive computations. The free monad transformer <code>FreeT</code> solves this problem by allowing us to mix building steps of the abstract syntax tree with calling actions in some base monad.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#66d9ef">data</span> <span style="color:#66d9ef">FreeF</span> f a x <span style="color:#f92672">=</span> <span style="color:#66d9ef">Pure</span> a <span style="color:#f92672">|</span> <span style="color:#66d9ef">Free</span> (f x)

<span style="color:#66d9ef">newtype</span> <span style="color:#66d9ef">FreeT</span> f m a <span style="color:#f92672">=</span> <span style="color:#66d9ef">FreeT</span> {
    runFreeT <span style="color:#f92672">::</span> m (<span style="color:#66d9ef">FreeF</span> f a (<span style="color:#66d9ef">FreeT</span> f m a)) }
</code></pre></div><p>We can see that <code>FreeT</code> gives us something very similar to the normal free monad, but with a monad <code>m</code> on the outside, where <code>m</code> is the extra effect.  This creates a tree where we go through it and execute some effects, but these effects are executed with respect to some other effect; so every step of computation (the nodes of the tree) is wrapped in an effect itself.</p>
<h5 id="23-an-example-use-of-free-monad-transformers">2.3 An Example Use of Free Monad Transformers</h5>
<p>For example, let&rsquo;s say we want to write our own Python-style generator. (Python generators are essentially coroutines. They are functions which when passed arguments, will run until encountering the <code>yield</code> keyword. Upon the <code>yield</code> keyword, it will return whatever value is &ldquo;yielded&rdquo;, and also save the state of the function at that point (under the name of the original function). Then, upon recalling the function, it will execute from immediately after the <em>yield</em>.)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#66d9ef">type</span> <span style="color:#66d9ef">Generator</span> a m r <span style="color:#f92672">=</span> <span style="color:#66d9ef">FreeT</span> ((,) a) m r
</code></pre></div><p>The type <code>Generator</code> is the free monad transformer where the functor <code>f</code> is <code>((,) a)</code> i.e. a partially applied tuple with the type <code>a</code> as its first argument, the monad is some arbitrary monad <code>m</code> as an effect, and it produces a result of arbitrary type <code>r</code>. Our functor being <code>((,) a)</code> means that the first element of the tuple of type <code>a</code> is the value that can be yielded, and the second element of the tuple represents the rest of the computation to be run (i.e. the continuation). The free monad transformer tree is a recursive structure that sequentially composes zero or more operations of the given functor <code>((,) a)</code> embedded within the context of monad <code>m</code>. The leaves of this tree are given by <code>Pure</code> of type <code>a</code>, and the nodes are operations <code>Free</code> that are shaped by <code>((,) a)</code> where the first element can be a yielded value and the second element contains the rest of the computation which can be run. The result of <code>return x</code> is a leaf, and <code>(&gt;&gt;=)</code> grows the tree of operations at its leaves.</p>
<p>Let&rsquo;s now look at an implementation of <code>yield</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#a6e22e">yield</span> <span style="color:#f92672">::</span> a <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">Generator</span> a m ()
<span style="color:#a6e22e">yield</span> a <span style="color:#f92672">=</span> liftF (a, ())
</code></pre></div><p>The function <code>yield</code> takes a value of type <code>a</code> that we want to yield, and lifts <code>(b, ())</code> into the free monad transformer type <code>FreeT ((,) a) m ()</code> &ndash; when we monadically extract the value from this, we get a tuple containing the yielded value <code>a</code> and a unit <code>()</code> representing the rest (or in this case, the end) of the computation.</p>
<p>Let&rsquo;s now look at an implementation of <code>prompt</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#a6e22e">prompt</span> <span style="color:#f92672">::</span> <span style="color:#66d9ef">Generator</span> <span style="color:#66d9ef">String</span> <span style="color:#66d9ef">IO</span> ()
<span style="color:#a6e22e">prompt</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">do</span>
    lift <span style="color:#f92672">$</span> putStrLn <span style="color:#e6db74">&#34;Enter a string:&#34;</span>
    str <span style="color:#f92672">&lt;-</span> lift getLine
    yield str
</code></pre></div><p>The function <code>prompt</code> takes a free monad transformer tree where the nodes are shaped by the functor <code>((,) String</code> meaning each node contains a string and some arbitrary type <code>r</code> &ndash; however in this case, <code>r</code> will be <code>()</code>. It also sets the monadic context of our tree to be <code>IO</code>, allowing us to attach <code>IO</code> actions to the operations/nodes of the tree. We choose to attach the <code>IO</code> effect of printing <code>&quot;Enter a string:&quot;</code> to the terminal and then prompting a terminal input from the user &ndash; this input is then yielded.</p>
<p>Next, we look at how the free monad transformer tree <code>prompt</code> can be run:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#a6e22e">putStrLnAllTheThings</span> <span style="color:#f92672">::</span> <span style="color:#66d9ef">Show</span> r <span style="color:#f92672">=&gt;</span> <span style="color:#66d9ef">FreeT</span> ((,) <span style="color:#66d9ef">String</span>) <span style="color:#66d9ef">IO</span> r <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">IO</span> r
<span style="color:#a6e22e">putStrLnAllTheThings</span> gen <span style="color:#f92672">=</span> <span style="color:#66d9ef">do</span>
    x <span style="color:#f92672">&lt;-</span> runFreeT gen
    <span style="color:#66d9ef">case</span> x <span style="color:#66d9ef">of</span>
        <span style="color:#66d9ef">Pure</span> r   
          <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">do</span> putStrLn <span style="color:#f92672">$</span> <span style="color:#e6db74">&#34;Result: &#34;</span> <span style="color:#f92672">++</span> show r
                return r
        <span style="color:#66d9ef">Free</span> (str, gen&#39; <span style="color:#f92672">::</span> <span style="color:#66d9ef">FreeT</span> ((,) <span style="color:#66d9ef">String</span>) <span style="color:#66d9ef">IO</span> r)
          <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">do</span> putStrLn <span style="color:#f92672">$</span> <span style="color:#e6db74">&#34;User entered: &#34;</span> <span style="color:#f92672">++</span> str
                putStrLnAllTheThings gen&#39;

<span style="color:#a6e22e">main</span> <span style="color:#f92672">=</span> putStrLnAllTheThings prompt
</code></pre></div><p>The function <code>putStrLnAllTheThings</code> takes a free monad transformer tree as an argument in the same form as <code>prompt</code> except allowing the result type <code>r</code> to be arbitrary (rather than fixed as <code>()</code>). Here is an example run of <code>main</code>:</p>
<pre><code>Enter a string:
hello
User entered: hello
Result: ()
</code></pre><p>If we wanted to define <code>prompt</code> to run forever, we could write the following, where <code>forever</code> executes the operation it is passed, ignores its result, and then recurses on itself:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#a6e22e">prompt</span> <span style="color:#f92672">::</span> <span style="color:#66d9ef">Generator</span> <span style="color:#66d9ef">String</span> <span style="color:#66d9ef">IO</span> r
<span style="color:#a6e22e">prompt</span> <span style="color:#f92672">=</span> forever <span style="color:#f92672">$</span> <span style="color:#66d9ef">do</span>
    lift <span style="color:#f92672">$</span> putStrLn <span style="color:#e6db74">&#34;Enter a string:&#34;</span>
    str <span style="color:#f92672">&lt;-</span> lift getLine
    yield str

<span style="color:#a6e22e">putStrLnAllTheThings</span> <span style="color:#f92672">::</span> <span style="color:#66d9ef">FreeT</span> ((,) <span style="color:#66d9ef">String</span>) <span style="color:#66d9ef">IO</span> r <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">IO</span> r
<span style="color:#a6e22e">putStrLnAllTheThings</span> gen <span style="color:#f92672">=</span> <span style="color:#66d9ef">do</span>
    x <span style="color:#f92672">&lt;-</span> runFreeT gen
    <span style="color:#66d9ef">case</span> x <span style="color:#66d9ef">of</span>
        <span style="color:#66d9ef">Pure</span> r   
          <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">do</span> return r
        <span style="color:#66d9ef">Free</span> (str, gen&#39; <span style="color:#f92672">::</span> <span style="color:#66d9ef">FreeT</span> ((,) <span style="color:#66d9ef">String</span>) <span style="color:#66d9ef">IO</span> r)
          <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">do</span> putStrLn <span style="color:#f92672">$</span> <span style="color:#e6db74">&#34;User entered: &#34;</span> <span style="color:#f92672">++</span> str
                putStrLnAllTheThings gen&#39;

<span style="color:#a6e22e">main</span> <span style="color:#f92672">=</span> putStrLnAllTheThings prompt
</code></pre></div><!-- raw HTML omitted -->
<p><strong>Summary: Free Monad Transformer</strong></p>
<p>The free monad transformer means that every step of the computation within the tree can be automatically embedded in an arbitrary monadic effect. This lets us be both abstract in the interpreter as well as the monadic effect we want to attach to the interpreter.</p>
<h4 id="3-the-traced-datatype">3. The Traced Datatype</h4>
<p>The following monad <code>Traced</code> is a tracing monad where only a subset of random choices are traced.</p>
<p><em>Bayes.Traced.Static</em></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#66d9ef">data</span> <span style="color:#66d9ef">Traced</span> m a
  <span style="color:#f92672">=</span> <span style="color:#66d9ef">Traced</span>
      { model     <span style="color:#f92672">::</span> <span style="color:#66d9ef">Weighted</span> (<span style="color:#66d9ef">FreeSampler</span> m) a,
        traceDist <span style="color:#f92672">::</span> m (<span style="color:#66d9ef">Trace</span> a)
      }
</code></pre></div><p>The notion here is that we have some model, such as an SIR model, which makes random decisions at certain points of the program. We want to be able to decouple what it means to make random choices (the actual implementation of randomness) from the syntax. The syntax is the description of the model but where the model&rsquo;s stochastic elements (i.e calls to random functions such as distributions) are just names. By supplying the syntax with randomness, we use the description of the stochastic model in a stochatic manner. This distinction can be described as the model as syntax vs the model as a realisation of a stochastic proces.</p>
<p>We want the syntax to describe doing some action, but we want what those random choices are to be chosen elsewhere. For example, consider if we have a program that needs to make a random effect, but we want that randomness to come from different places i.e. we want to give it different ways of generating random numbers at each point. To elaborate, the program using the same deterministic random number at every point of random decision, versus the program using <code>-user-rand</code> at every point of random decision, are two distinctly different ways to do randomness.</p>
<p>The reason this is important with respect to tracing in probabilistic programming, is that the way one performs inference over an execution trace requires one to modify the trace of the program, the trace being all the random decisions made. Hence, we don&rsquo;t make any changes to the syntax of the program, we only work with the random decisions performed during the program (by making random changes to these random decisions). The first thing we need is a way to decouple these two things, which is what the <code>Traced</code> datatype achieves by having two distinct fields:</p>
<ul>
<li>
<p>The <code>model</code> field, which is a description of the suspended model as a syntax, separated from its random decisions. The model is the abstract interpreter which defines our program, augmented in this free monad transformer with where the random decisions to be made <em>would</em> be. One could imagine this as a tree of random decisions waiting for their source of randomness. The implementation of the model itself will most likely be associated with drawing from various distributions, which are themselves random decisions, but for such random actions to be performed, we first need to provide a source of randomness as a &ldquo;seed&rdquo;.</p>
</li>
<li>
<p>The <code>traceDist</code> field, which provides the model with a source of randomness in order to realise the model as a stochastic process.</p>
</li>
</ul>
<p>We will now elaborate on what these two fields of <code>Traced</code> are:</p>
<h5 id="31-the-freesampler-datatype-bayesfree">3.1 The FreeSampler Datatype (Bayes.Free)</h5>
<p>Let&rsquo;s first inspect the <code>model</code> field of <code>Traced</code>.</p>
<p><em>Bayes.Traced.Static</em></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#66d9ef">data</span> <span style="color:#66d9ef">Traced</span> m a
  <span style="color:#f92672">=</span> <span style="color:#66d9ef">Traced</span>
      { model     <span style="color:#f92672">::</span> <span style="color:#66d9ef">Weighted</span> (<span style="color:#66d9ef">FreeSampler</span> m) a,
        <span style="color:#f92672">...</span> }
</code></pre></div><p>This involves us looking at what the type <code>FreeSampler</code> is.</p>
<p><em>Bayes.Free</em></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#75715e">-- | Random sampling functor.</span>
<span style="color:#66d9ef">newtype</span> <span style="color:#66d9ef">SamF</span> a <span style="color:#f92672">=</span> <span style="color:#66d9ef">Random</span> (<span style="color:#66d9ef">Double</span> <span style="color:#f92672">-&gt;</span> a)

<span style="color:#66d9ef">instance</span> <span style="color:#66d9ef">Functor</span> <span style="color:#66d9ef">SamF</span> <span style="color:#66d9ef">where</span>
  fmap f (<span style="color:#66d9ef">Random</span> k) <span style="color:#f92672">=</span> <span style="color:#66d9ef">Random</span> (f <span style="color:#f92672">.</span> k)

<span style="color:#75715e">-- | Free monad transformer over random sampling.</span>
<span style="color:#66d9ef">newtype</span> <span style="color:#66d9ef">FreeSampler</span> m a <span style="color:#f92672">=</span> <span style="color:#66d9ef">FreeSampler</span> {runFreeSampler <span style="color:#f92672">::</span> <span style="color:#66d9ef">FT</span> <span style="color:#66d9ef">SamF</span> m a}
  <span style="color:#66d9ef">deriving</span> (<span style="color:#66d9ef">Functor</span>, <span style="color:#66d9ef">Applicative</span>, <span style="color:#66d9ef">Monad</span>, <span style="color:#66d9ef">MonadTrans</span>)
</code></pre></div><p>The type <code>FreeSampler</code> is essentially the free monad transformer <code>FT</code> where the functor (shape of the tree&rsquo;s nodes) is specified as the type <code>SamF</code>, and the monadic context we wrap our nodes in is left abstract.</p>
<p>The type <code>SamF</code> is the random sampling functor, which represents the idea of a random effect. It captures the notion that we provide a (random) <code>Double</code> and it returns some value of type <code>a</code>, i.e. the notion that we make a random decision at some point.</p>
<p>The type <code>FT SamF m a</code> is hence the free monad tree of random decisions. In some sense, this is the composition of a bunch of functions which take <code>Double</code>s and return us <code>a</code>s. Imagine a tree where every step of the tree we provide it a random number as a <code>Double</code> which is then mapped to a value as an <code>a</code> &ndash; we can then consider this <code>a</code> to be a random value. The type <code>a</code> represents whatever we want samples of. We can think of <code>(Double -&gt; a)</code> as a specification for a random number generator - a random number generator takes some seed as a double and produces a random value in type <code>a</code>.</p>
<p>&ldquo;So what does the free sampler <code>FT SamF m a</code> allow us to do?&rdquo; Let&rsquo;s take a look at the function <code>withRandomness</code>: this executes a computation with supplied values for random choices.</p>
<p><em>Bayes.Free</em></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#75715e">-- | Execute computation with supplied values for random choices.</span>
<span style="color:#a6e22e">withRandomness</span> <span style="color:#f92672">::</span> <span style="color:#66d9ef">Monad</span> m <span style="color:#f92672">=&gt;</span> [<span style="color:#66d9ef">Double</span>] <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">FreeSampler</span> m a <span style="color:#f92672">-&gt;</span> m a
<span style="color:#a6e22e">withRandomness</span> randomness (<span style="color:#66d9ef">FreeSampler</span> m) <span style="color:#f92672">=</span> evalStateT (iterTM f m) randomness
  <span style="color:#66d9ef">where</span>
    f (<span style="color:#66d9ef">Random</span> k) <span style="color:#f92672">=</span> <span style="color:#66d9ef">do</span>
      xs <span style="color:#f92672">&lt;-</span> get
      <span style="color:#66d9ef">case</span> xs <span style="color:#66d9ef">of</span>
        <span style="color:#66d9ef">[]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#a6e22e">error</span> <span style="color:#e6db74">&#34;FreeSampler: the list of randomness was too short&#34;</span>
        y <span style="color:#66d9ef">:</span> ys <span style="color:#f92672">-&gt;</span> put ys <span style="color:#f92672">&gt;&gt;</span> k y
</code></pre></div><p>It takes a list of random doubles and a free monad tree of random decisions waiting to happen. We can imagine that <code>m</code> is the computation we want to execute, and embedded in this is some source of randomness given by the <code>SamF</code> functor, or more specifically, the <code>Random k</code> where <code>k :: Double -&gt; a</code> &ndash; however, we need to provide a random <code>Double</code> to <code>k</code> each time in order to achieve this randomness. How this list of random <code>Double</code>s is generated in the first place, is up to the user.</p>
<p>What trace mcmc will do in order to do inference, is mess around with/modify this list of doubles supplied and see what the consequent program output will be. The approach given in <a href="https://web.stanford.edu/~ngoodman/papers/lightweight-mcmc-aistats2011.pdf">Lightweight Implementations of Probabilistic Programming Languages</a> for probabilistic programming via trace mcmc, treats trace mcmc as a meta-program. It takes the source code of the program, and it takes the source of randomness, and it does some meta-level programming to rewrite the source code, naming each of the original random functions <code>f_k</code>, and then replacing them with deterministic functions <code>f'_k</code>. When these deterministic functions are encountered in the execution trace, they deterministically use their name to look up a current value <code>x_k</code> in a database and return it to be used as the random double. For each full run of the program, the doubles stored in the database are manipulated in order to perform inference.</p>
<p>However it turns out that if we use the free monad transformer, we are producing the abstract interpreter of the program within the language itself. In other words, the free monad transformer lets us internalize the approach described in the paper within the language, without any meta-programming. In monad-bayes, rather than naming each random function <code>f_k</code> to associate it with a random double stored in a database, we treat the &ldquo;names&rdquo; as the nodes/steps in the free monad transformer tree, each of which corresponds to an index in a list of random doubles &ndash; so the k&rsquo;th step in the tree can be mapped to the k&rsquo;th index in the list of random doubles. So instead of doing things by &ldquo;name&rdquo;, we create associations between random functions and their random doubles by order in a list. The list&rsquo;s elements matches up with the sequential nature of the program.</p>
<h5 id="32-the-trace-datatype-bayestracedcommon">3.2 The Trace Datatype (Bayes.Traced.Common)</h5>
<p>Let&rsquo;s now inspect the <code>traceDist</code> field of <code>Traced</code>.</p>
<p><em>Bayes.Traced.Static</em></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#66d9ef">data</span> <span style="color:#66d9ef">Traced</span> m a
  <span style="color:#f92672">=</span> <span style="color:#66d9ef">Traced</span>
      { <span style="color:#f92672">...</span> ,
        traceDist <span style="color:#f92672">::</span> m (<span style="color:#66d9ef">Trace</span> a)
      }
</code></pre></div><p>This involves looking at how the trace datatype <code>Trace</code> is defined:</p>
<p><em>Bayes.Traced.Common</em></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#75715e">-- | Collection of random variables sampled during the program&#39;s execution.</span>
<span style="color:#66d9ef">data</span> <span style="color:#66d9ef">Trace</span> a
  <span style="color:#f92672">=</span> <span style="color:#66d9ef">Trace</span>
      { <span style="color:#75715e">-- | Sequence of particular realisations of random variables sampled during the program&#39;s execution.</span>
        variables <span style="color:#f92672">::</span> <span style="color:#f92672">!</span>([<span style="color:#66d9ef">Double</span>]),
        <span style="color:#75715e">-- |</span>
        output <span style="color:#f92672">::</span> <span style="color:#f92672">!</span>a,
        <span style="color:#75715e">-- | The probability of observing this particular sequence.</span>
        density <span style="color:#f92672">::</span> <span style="color:#75715e">{-# UNPACK #-}</span> <span style="color:#f92672">!</span>(<span style="color:#66d9ef">Log</span> <span style="color:#66d9ef">Double</span>)
      }
</code></pre></div><p>This contains three things:</p>
<ul>
<li>The <code>variables</code> are the list of random doubles that we supply to the model/program during execution, where each double corresponds to a computational step of randomness in the program. This is the list that we must modify values of in order to observe new results and then perform inference over.</li>
<li>The <code>output</code> is the result of running a given model using the current variables (the list of random doubles).</li>
<li>The <code>density</code> is the probability density of the sequence of doubles, <code>variables</code>, giving rise to the output <code>b</code>, given some external model.</li>
</ul>
<h4 id="4-the-trace-metropolis-hastings-function">4. The Trace Metropolis-Hastings Function</h4>
<h5 id="41-trace-metropolis-hastings">4.1 Trace Metropolis-Hastings</h5>
<p>Let&rsquo;s now have a look at how the <code>Traced</code> data type is used in the implementation of trace metropolis-hastings (a method of inference of the posterior), by inspecting the function <code>mh</code>.</p>
<p><em>Bayes.Traced.Static</em></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#75715e">-- | Full run of the Trace Metropolis-Hastings algorithm with a specified</span>
<span style="color:#75715e">--   number of steps.</span>
<span style="color:#a6e22e">mh</span> <span style="color:#f92672">::</span> <span style="color:#66d9ef">MonadSample</span> m <span style="color:#f92672">=&gt;</span> <span style="color:#66d9ef">Int</span> <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">Traced</span> m a <span style="color:#f92672">-&gt;</span> m [a]
<span style="color:#a6e22e">mh</span> n (<span style="color:#66d9ef">Traced</span> m d) <span style="color:#f92672">=</span> fmap (map output) (f n)
  <span style="color:#66d9ef">where</span>
    f <span style="color:#ae81ff">0</span> <span style="color:#f92672">=</span> fmap (<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">[]</span>) d
    f k <span style="color:#f92672">=</span> <span style="color:#66d9ef">do</span>
      <span style="color:#f92672">~</span>(x <span style="color:#66d9ef">:</span> xs) <span style="color:#f92672">&lt;-</span> f (k <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
      y <span style="color:#f92672">&lt;-</span> mhTrans m x
      return (y <span style="color:#66d9ef">:</span> x <span style="color:#66d9ef">:</span> xs)
</code></pre></div><p>The function <code>mh</code> represents the traced metropolis-hastings algorithm, (where metropolis-hastings is a markov chain monte carlo method for obtaining a sequence of random samples from a probability distribution).</p>
<p>For a specified number of steps, <code>n</code>, it runs <code>mhTrans</code> on the model <code>m</code> (given by the field <code>model :: Weighted (FreeSampler m a)</code> of <code>Traced</code>) and the current trace <code>x</code> (given by extracting the result from the field <code>traceDist :: m (Trace a)</code> of <code>Traced</code>).</p>
<p>The function <code>f</code> then returns the history of all the different values of the <code>Trace</code> data type used during each call to <code>mhTrans</code>. By calling <code>fmap (map output)</code> on this list of <code>Trace</code> values, we extract all the <code>output</code>s of the model produced during each metropolis-hastings step. Note that although the  <code>variables</code> and the <code>density</code> of the current <code>Trace</code> are needed for each step of metropolis-hastings (see <code>mhTrans</code>) in order to &ldquo;optimise&rdquo; the <code>Trace</code> as we progress during inference, at the end of the entire metropolis-hastings algorithm, we are only interested in recording all the <code>output</code>s which are accepted. The history of all the <code>output</code>s are what form the markov chain, and in theory, these <code>output</code>s are all the samples of which a histogram of will form our <em>posterior distribution</em>, i.e. our end goal.</p>
<h5 id="42-a-single-step-of-trace-metropolis-hastings">4.2 A Single Step of Trace Metropolis-Hastings</h5>
<p>The function <code>mhTrans</code> performs a single step of trace metropolis-hastings. Let&rsquo;s now take a look at it:</p>
<p><em>Bayes.Traced.Common</em></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#75715e">-- | A single Metropolis-corrected transition of single-site Trace MCMC.</span>
<span style="color:#a6e22e">mhTrans</span> <span style="color:#f92672">::</span> <span style="color:#66d9ef">MonadSample</span> m <span style="color:#f92672">=&gt;</span> <span style="color:#66d9ef">Weighted</span> (<span style="color:#66d9ef">FreeSampler</span> m) a <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">Trace</span> a <span style="color:#f92672">-&gt;</span> m (<span style="color:#66d9ef">Trace</span> a)
<span style="color:#a6e22e">mhTrans</span> m t<span style="color:#f92672">@</span><span style="color:#66d9ef">Trace</span> {variables <span style="color:#f92672">=</span> us, density <span style="color:#f92672">=</span> p} <span style="color:#f92672">=</span> <span style="color:#66d9ef">do</span>
  <span style="color:#66d9ef">let</span> n <span style="color:#f92672">=</span> length us
  us&#39; <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">do</span> <span style="color:#75715e">-- :: m [Log Double]</span>
    i <span style="color:#f92672">&lt;-</span> discrete <span style="color:#f92672">$</span> discreteUniformAB <span style="color:#ae81ff">0</span> (n <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>)
    u&#39; <span style="color:#f92672">&lt;-</span> random
    <span style="color:#66d9ef">let</span> (xs, <span style="color:#66d9ef">_</span> <span style="color:#66d9ef">:</span> ys) <span style="color:#f92672">=</span> splitAt i us
    return <span style="color:#f92672">$</span> xs <span style="color:#f92672">++</span> (u&#39; <span style="color:#66d9ef">:</span> ys)
  ((b, q), vs) <span style="color:#f92672">&lt;-</span> runWriterT <span style="color:#f92672">$</span> runWeighted <span style="color:#f92672">$</span> <span style="color:#66d9ef">Weighted</span><span style="color:#f92672">.</span>hoist (<span style="color:#66d9ef">WriterT</span> <span style="color:#f92672">.</span> withPartialRandomness us&#39;) m
  <span style="color:#66d9ef">let</span> ratio <span style="color:#f92672">=</span> (exp <span style="color:#f92672">.</span> ln) <span style="color:#f92672">$</span> min <span style="color:#ae81ff">1</span> (q <span style="color:#f92672">*</span> fromIntegral n <span style="color:#f92672">/</span> (p <span style="color:#f92672">*</span> fromIntegral (length vs)))
  accept <span style="color:#f92672">&lt;-</span> bernoulli ratio
  return <span style="color:#f92672">$</span> <span style="color:#66d9ef">if</span> accept <span style="color:#66d9ef">then</span> <span style="color:#66d9ef">Trace</span> vs b q <span style="color:#66d9ef">else</span> t
</code></pre></div><p>This function takes as inputs the model we&rsquo;re performing inference over (i.e. the free tree containing computational steps of random decisions), and the current trace (of which we are only interested in the variables and the density).</p>
<ol>
<li>The block of do-notation following <code>us' &lt;- do</code> describes the act of reassigning the value of a double in the list of random doubles. The way we do this is we first randomly select an index in this list, given by <code>i &lt;- discrete $ discreteUniformAB 0 (n - 1)</code>. Next, we generate a new random value, given by <code>u' &lt;- random</code>. Finally, we insert the new random value in the list, given by <code>let (xs, _ : ys) = splitAt i us; return $ xs ++ (u' : ys)</code>.</li>
</ol>
<!-- raw HTML omitted -->
<ol start="2">
<li>
<p>Given this updated list, we re-run the model with the new source of randomness, seen in <code>((b, q), vs) &lt;- runWriterT $ runWeighted $ Weighted.hoist (WriterT . withPartialRandomness us') m</code>, where <code>b</code> is the model&rsquo;s observed output, <code>vs</code> is the list of random doubles used to run the model, and <code>q</code> is the probability density of the sequence of doubles <code>vs</code> used giving rise to the output <code>b</code>. (The density is the joint probability of getting all the realisations of the random variables).</p>
<p>Note that <code>us'</code> and <code>vs</code> will be the same only if the list of randomness <code>us'</code> is the same length as the number of steps of random decisions made during the program (i.e. the same length as the number of nodes in the free monad transformer tree). If only a subset of random doubles is provided (i.e. the list is shorter than the tree), then the function <code>withPartialRandomness</code> will create new random values for us and append them to the list <code>us'</code>. If the list <code>us'</code> is too long, then the returned list <code>vs</code> will contain only the list of random doubles of <code>us'</code> used during execution (hence <code>vs</code> will always be the same length as the free tree).</p>
</li>
</ol>
<!-- raw HTML omitted -->
<ol start="3">
<li>Then we determine whether the resulting probability density <code>q</code> of observing the current sequence of doubles used, <code>vs'</code>, is better or worse than the probability density <code>p</code> of observing the previous sequence of doubles used, <code>us</code>. We do this by evaluating the &ldquo;ratio&rdquo; given by <code>let ratio = (exp . ln) $ min 1 (q * fromIntegral n / (p * fromIntegral (length vs)))</code>, and then passing the ratio to a bernoulli function, which returns us a boolean telling us whether to accept or reject the new proposed sequence of doubles. If we accept, then we return the new trace data type, otherwise, we retain the old one.</li>
</ol>
<p><strong>Summary: Trace Metropolis-Hastings</strong></p>
<p>The function <code>mh</code> hence is an iterative process of randomly updating the list of random doubles as a new proposal (stored inside the <code>Trace</code> data type), running the model to see whether the output has a better probability density of yielding the provided list of random doubles, and updating the <code>Trace</code> data type whenever the probability density satisfies the acceptance ratio. In a sense, we are keeping the execution trace which is best &ndash; because the execution trace fully defines the program, we know what the parameters are. Note that we never make changes to the model itself.</p>
<p>The reason trace mcmc can be viewed as &ldquo;better&rdquo; than normal mcmc, is that it is more general. In normal metropolis hastings, one has to specify what the parameters of the model are. In trace mcmc, the parameters automatically become the random doubles associated with each random computational step in the program &ndash; what we are doing is performing metropolis-hastings on the execution trace of the program itself. The trace gives us all the information about <em>all</em> the random decisions performed in the program, i.e. everything about the probabilistic nature of the program. Hence, the algorithm will work for all programming languages. The downside to performing inference over <em>all</em> the random decisions made in the program, is that not all random decisions may be related to the parameters of the model we are interested in.</p>
<p>For example, the following block of code inside the function <code>mhTrans</code> which randomly selects an index in the list of doubles to change, is a fairly naive, brute-force approach to inference.</p>
<p><em>Bayes.Traced.Common</em></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell">  us&#39; <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">do</span> <span style="color:#75715e">-- :: m [Log Double]</span>
    i <span style="color:#f92672">&lt;-</span> discrete <span style="color:#f92672">$</span> discreteUniformAB <span style="color:#ae81ff">0</span> (n <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>)
    u&#39; <span style="color:#f92672">&lt;-</span> random
    <span style="color:#66d9ef">let</span> (xs, <span style="color:#66d9ef">_</span> <span style="color:#66d9ef">:</span> ys) <span style="color:#f92672">=</span> splitAt i us
    return <span style="color:#f92672">$</span> xs <span style="color:#f92672">++</span> (u&#39; <span style="color:#66d9ef">:</span> ys)
</code></pre></div><p>So how does one recognise which random decisions in the program are actually important to the parameters of our model? This is a question that currently needs more looking in to.</p>
<hr>
<h4 id="5-pmmh-bayesinferencepmmh">5. PMMH (Bayes.Inference.PMMH)</h4>
<p>Given a prior and a likelihood function, normal metropolis-hastings is an algorithm for producing samples from the posterior distribution, and hence allows us to approximate the posterior without having the analytic formulation of the normalising constant.</p>
<p>PMMH or PMCMC methods are normal MH/MCMC algorithms where we don&rsquo;t have the analytic formulation of the likelihood function, so it is instead replaced by a particle filter as an approximation to the likelihood function (we can run a particle filter, and at the end, we can extract an estimate of the likelihood function from this).</p>
<p><em>Bayes.Inference.PMMH</em></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#a6e22e">pmmh</span> <span style="color:#f92672">::</span>
  <span style="color:#66d9ef">MonadInfer</span> m <span style="color:#f92672">=&gt;</span>
  <span style="color:#75715e">-- | number of Metropolis-Hastings steps</span>
  <span style="color:#66d9ef">Int</span> <span style="color:#f92672">-&gt;</span>
  <span style="color:#75715e">-- | number of time steps</span>
  <span style="color:#66d9ef">Int</span> <span style="color:#f92672">-&gt;</span>
  <span style="color:#75715e">-- | number of particles</span>
  <span style="color:#66d9ef">Int</span> <span style="color:#f92672">-&gt;</span>
  <span style="color:#75715e">-- | model parameters prior</span>
  <span style="color:#66d9ef">Traced</span> m b <span style="color:#f92672">-&gt;</span>
  <span style="color:#75715e">-- | model</span>
  (b <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">Sequential</span> (<span style="color:#66d9ef">Population</span> m) a) <span style="color:#f92672">-&gt;</span>
  m [[(a, <span style="color:#66d9ef">Log</span> <span style="color:#66d9ef">Double</span>)]]
<span style="color:#a6e22e">pmmh</span> t k n param model <span style="color:#f92672">=</span>
  mh t (param <span style="color:#f92672">&gt;&gt;=</span> runPopulation <span style="color:#f92672">.</span> pushEvidence <span style="color:#f92672">.</span> <span style="color:#66d9ef">Pop</span><span style="color:#f92672">.</span>hoist lift <span style="color:#f92672">.</span>
        smcSystematic k n <span style="color:#f92672">.</span> model)
</code></pre></div><p>We can imagine that PMMH as a function is something which runs metropolis-hastings (<code>mh</code>) given a prior (<code>params</code>) and a likelihood function (<code>runPopulation . pushEvidence . Pop.hoist lift . smcSystematic k n . model</code>).</p>
<ul>
<li>
<p><code>smcSystematic</code> - the particle filter (Sequential Monte Carlo) which uses systematic resampling at each timestep as a resampling method. Hence composing <code>smcSystematic</code> with <code>model</code> is running the particle filter on the model we give it. What we are doing with a particle filter is simulating a set of particles with their associated weights, and it turns out that summing these weights is an estimate of the likelihood.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#75715e">-- | Sequential Monte Carlo with systematic resampling at each timestep.</span>
<span style="color:#75715e">-- Weights are not normalized.</span>
<span style="color:#a6e22e">smcSystematic</span> <span style="color:#f92672">::</span>
  <span style="color:#66d9ef">MonadSample</span> m <span style="color:#f92672">=&gt;</span>
  <span style="color:#75715e">-- | number of timesteps</span>
  <span style="color:#66d9ef">Int</span> <span style="color:#f92672">-&gt;</span>
  <span style="color:#75715e">-- | number of particles</span>
  <span style="color:#66d9ef">Int</span> <span style="color:#f92672">-&gt;</span>
  <span style="color:#75715e">-- | model</span>
  <span style="color:#66d9ef">Sequential</span> (<span style="color:#66d9ef">Population</span> m) a <span style="color:#f92672">-&gt;</span>
  <span style="color:#66d9ef">Population</span> m a
<span style="color:#a6e22e">smcSystematic</span> <span style="color:#f92672">=</span> sir resampleSystematic
</code></pre></div></li>
</ul>
<!-- raw HTML omitted -->
<ul>
<li>
<p><code>Pop.hoist lift</code> has type <code>Population m a -&gt; Population n a</code> &ndash; specifically in this case, it will have type <code>Population m a -&gt; Population (Traced m) a</code>, i think, because <code>lift</code> will be from the <code>MonadTrans</code> instance of <code>Traced</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#a6e22e">hoist</span> <span style="color:#f92672">::</span>
  (<span style="color:#66d9ef">Monad</span> m, <span style="color:#66d9ef">Monad</span> n) <span style="color:#f92672">=&gt;</span>
  (forall x<span style="color:#f92672">.</span> m x <span style="color:#f92672">-&gt;</span> n x) <span style="color:#f92672">-&gt;</span>
  <span style="color:#66d9ef">Population</span> m a <span style="color:#f92672">-&gt;</span>
  <span style="color:#66d9ef">Population</span> n a
<span style="color:#a6e22e">hoist</span> f <span style="color:#f92672">=</span> fromWeightedList <span style="color:#f92672">.</span> f <span style="color:#f92672">.</span> runPopulation
</code></pre></div></li>
</ul>
<!-- raw HTML omitted -->
<ul>
<li>
<p><code>pushEvidence</code> - the step which allows us to get the likelihood function from the particle filter.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#75715e">-- | Push the evidence estimator as a score to the transformed monad.</span>
<span style="color:#75715e">-- Weights are normalized after this operation.</span>
<span style="color:#a6e22e">pushEvidence</span> <span style="color:#f92672">::</span>
  <span style="color:#66d9ef">MonadCond</span> m <span style="color:#f92672">=&gt;</span>
  <span style="color:#66d9ef">Population</span> m a <span style="color:#f92672">-&gt;</span>
  <span style="color:#66d9ef">Population</span> m a
<span style="color:#a6e22e">pushEvidence</span> <span style="color:#f92672">=</span> (hoist applyWeight) <span style="color:#f92672">.</span> extractEvidence
<span style="color:#75715e">-- extractEvidence   :: Population m a -&gt; Population (Weighted m)</span>
<span style="color:#75715e">-- hoist applyWeight :: Population (Weighted m a) -&gt; Population m a </span>
</code></pre></div></li>
</ul>
<div class="edit-meta">
Last updated on 13 Nov 2020


<br>
Published on 13 Nov 2020
<br></div><nav class="pagination"><a class="nav nav-prev" href="https://probabilistic-effects.github.io/monad-bayes/pmmh-hmm/" title="Implementing HMM Simulation and Inference (using PMMH)"><i class="fas fa-arrow-left" aria-hidden="true"></i> Prev - Implementing HMM Simulation and Inference (using PMMH)</a>
<a class="nav nav-next" href="https://probabilistic-effects.github.io/monad-bayes/conditioning-scoring/" title="How Conditioning and Scoring Works">Next - How Conditioning and Scoring Works <i class="fas fa-arrow-right" aria-hidden="true"></i></a>
</nav><footer><p class="powered">Powered by <a href="https://gohugo.io">Hugo</a>. Theme by <a href="https://themes.gohugo.io/hugo-theme-techdoc/">TechDoc</a>. Designed by <a href="https://github.com/thingsym/hugo-theme-techdoc">Thingsym</a>.</p>
</footer>
</main>
<div class="sidebar">

<nav class="open-menu">
<ul>
<li class=""><a href="https://probabilistic-effects.github.io/">Home</a></li>

<li class=""><a href="https://probabilistic-effects.github.io/activity/">Activity</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/activity/cpsing-monad-bayes/">CPSing Monad Bayes</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/activity/inlining-monad-bayes/">Inlining Monad Bayes</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/papers/">Papers</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/papers/asymptotic-improvement/">Asymptotic Improvement of Computations over Free Monads</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/papers/faster-coroutine-pipelines/">Faster Coroutine Pipelines</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/papers/freer-monads/">Freer Monads, More Extensible Effects</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/papers/fusion-for-free/">Fusion for Free</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/papers/probabilistic-programming/">Introduction To Probabilistic Programming</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/papers/lightweight-implementations-prob-languages/">Lightweight Implementations of Probabilistic Programming Languages</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/research/">Research</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/research/research-journal/">Research Journal</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/approaches-for-monad-bayes/">Potential Approaches to Improving Monad Bayes</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/effects-for-less/">Effects for Less</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/literature-review/">Literature Review</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/parsley-case-study/">Case Study: Optimising Parsley</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/optimising-core/">Optimising Core</a></li>
</ul>
  
</li>

<li class="parent"><a href="https://probabilistic-effects.github.io/monad-bayes/">Monad Bayes</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/inference-transformers/">Inference Transformers</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/pmmh-hmm/">Implementing HMM Simulation and Inference (using PMMH)</a></li>
<li class="active"><a href="https://probabilistic-effects.github.io/monad-bayes/documentation/">Documentation</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/conditioning-scoring/">How Conditioning and Scoring Works</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/tooling/">Tooling</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/tooling/cabal/">Cabal Projects</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/">Benchmarking</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/benchmark-log/">Benchmark Log</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/benchmarking-profiling/">How to Benchmark and Profile</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/monad-bayes-components/">Relevant Components of Monad Bayes for Profiling</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/background/">Background</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/background/staging/">Staging</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/smc-pmmh/">SMC and PMMH</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/handrolling/">Handrolling Monad Transformer Stacks</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/mtl/">MTL</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/mcmc-mh/">MCMC and MH</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/markov-chain/">Markov Chains</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/hidden-markov-model/">Hidden Markov Model</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/delimited-continuations/">Delimited Continuations</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/haskell-core/">Haskell Core</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/inlining/">Inlining</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/specialisation/">Specialisation</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/continuations/">Continuations</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/coroutines/">Coroutines</a></li>
</ul>
  
</li>
</ul>
</nav>



<div class="sidebar-footer"></div>
</div>

</div><a href="#" id="backtothetop-fixed" class="backtothetop"
 data-backtothetop-duration="600"
 data-backtothetop-easing="easeOutQuart"
 data-backtothetop-fixed-fadeIn="1000"
 data-backtothetop-fixed-fadeOut="1000"
 data-backtothetop-fixed-bottom="10"
 data-backtothetop-fixed-right="20">
<span class="fa-layers fa-fw">
<i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i>
</span></a>
</div>
</body>
</html>
