<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<title>Probabilistic Language Design - Probabilistic Effects.  λθ</title>
<meta name="generator" content="Hugo 0.80.0" />
<link href="https://probabilistic-effects.github.io//index.xml" rel="alternate" type="application/rss+xml">
<link rel="canonical" href="https://probabilistic-effects.github.io/research/probabilistic-design/">
<link rel="stylesheet" href="https://probabilistic-effects.github.io/css/theme.min.css">
<script src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>
<link rel="stylesheet" href="https://probabilistic-effects.github.io/css/chroma.min.css">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script>
<script src="https://probabilistic-effects.github.io/js/bundle.js"></script><style>
:root {}
</style>
<meta property="og:title" content="Probabilistic Language Design" />
<meta property="og:description" content="Relevant Existing Probabilistic Programming Libraries/Languages
        Probabilistic Language Design
The Design and Implementation of Probabilistic Programming Languages (Learning Resource) - Noah D. Goodman and Andreas Stuhlmüller
Usability of Probabilistic Programming Languages
Embedded Domain-Specific Languages for Probabilistic Programming - Oleg Kiselyov&rsquo;s Page
 Probabilistic Programming Language and its Incremental Evaluation (Hakaru10, Graphical Models) - Oleg Kiselyov, 2016 Probabilistic inference by program transformation in Hakaru - Praveen Narayanan, Chung-chieh Shan, 2016 Embedded Probabilistic Programming (Hansei) - Oleg Kiselyov, IFIP 2009  Functional probabilistic programming for scalable Bayesian modelling - Jonathan Law, Darren J." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://probabilistic-effects.github.io/research/probabilistic-design/" />
<meta property="article:published_time" content="2020-11-13T14:05:41+00:00" />
<meta property="article:modified_time" content="2020-11-13T14:05:41+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Probabilistic Language Design"/>
<meta name="twitter:description" content="Relevant Existing Probabilistic Programming Libraries/Languages
        Probabilistic Language Design
The Design and Implementation of Probabilistic Programming Languages (Learning Resource) - Noah D. Goodman and Andreas Stuhlmüller
Usability of Probabilistic Programming Languages
Embedded Domain-Specific Languages for Probabilistic Programming - Oleg Kiselyov&rsquo;s Page
 Probabilistic Programming Language and its Incremental Evaluation (Hakaru10, Graphical Models) - Oleg Kiselyov, 2016 Probabilistic inference by program transformation in Hakaru - Praveen Narayanan, Chung-chieh Shan, 2016 Embedded Probabilistic Programming (Hansei) - Oleg Kiselyov, IFIP 2009  Functional probabilistic programming for scalable Bayesian modelling - Jonathan Law, Darren J."/>
<meta itemprop="name" content="Probabilistic Language Design">
<meta itemprop="description" content="Relevant Existing Probabilistic Programming Libraries/Languages
        Probabilistic Language Design
The Design and Implementation of Probabilistic Programming Languages (Learning Resource) - Noah D. Goodman and Andreas Stuhlmüller
Usability of Probabilistic Programming Languages
Embedded Domain-Specific Languages for Probabilistic Programming - Oleg Kiselyov&rsquo;s Page
 Probabilistic Programming Language and its Incremental Evaluation (Hakaru10, Graphical Models) - Oleg Kiselyov, 2016 Probabilistic inference by program transformation in Hakaru - Praveen Narayanan, Chung-chieh Shan, 2016 Embedded Probabilistic Programming (Hansei) - Oleg Kiselyov, IFIP 2009  Functional probabilistic programming for scalable Bayesian modelling - Jonathan Law, Darren J.">
<meta itemprop="datePublished" content="2020-11-13T14:05:41+00:00" />
<meta itemprop="dateModified" content="2020-11-13T14:05:41+00:00" />
<meta itemprop="wordCount" content="1327">



<meta itemprop="keywords" content="" />
</head>
<body><div class="container"><header>
<h1>Probabilistic Effects.  λθ</h1>
</header>

<div class="content-container">
<main><h1>Probabilistic Language Design</h1>
<p><strong>Relevant Existing Probabilistic Programming Libraries/Languages</strong></p>
<ul>
<li><img src="https://hakaru-dev.github.io/" alt="Hakuru"></li>
<li><img src="http://okmij.org/ftp/kakuritu/Hansei.html" alt="Hansei"></li>
<li><img src="https://hackage.haskell.org/package/probability" alt="probability"></li>
<li><img src="https://hackage.haskell.org/package/monad-bayes" alt="monad-bayes"></li>
<li><img src="https://probprog.github.io/anglican/index.html" alt="Anglican"></li>
<li><img src="https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers" alt="PyMC"></li>
</ul>
<p><strong>Probabilistic Language Design</strong></p>
<p><a href="http://dippl.org/">The Design and Implementation of Probabilistic Programming Languages (Learning Resource) - Noah D. Goodman and Andreas Stuhlmüller</a></p>
<p><a href="https://www.cl.cam.ac.uk/~afb21/publications/PPIG2019-accepted.pdf">Usability of Probabilistic Programming Languages</a></p>
<p><a href="http://okmij.org/ftp/kakuritu/">Embedded Domain-Specific Languages for Probabilistic Programming - Oleg Kiselyov&rsquo;s Page</a></p>
<ul>
<li><a href="http://okmij.org/ftp/kakuritu/Hakaru10/design.pdf">Probabilistic Programming Language and its Incremental Evaluation (Hakaru10, Graphical Models) - Oleg Kiselyov, 2016</a></li>
<li><a href="https://wrengr.org/pubs/hakaru_flops2016.pdf">Probabilistic inference by program transformation in Hakaru - Praveen Narayanan, Chung-chieh Shan, 2016</a></li>
<li><a href="https://link.springer.com/content/pdf/10.1007/978-3-642-03034-5_17.pdf">Embedded Probabilistic Programming (Hansei) - Oleg Kiselyov, IFIP 2009</a></li>
</ul>
<p><a href="https://arxiv.org/pdf/1908.02062.pdf">Functional probabilistic programming for scalable Bayesian modelling - Jonathan Law, Darren J. Wilkinson, Alan Turing Institute, 2019</a></p>
<p><a href="http://www.denotational.co.uk/publications/scibior-kammar-ghahramani-funcitonal-programming-for-modular-bayesian-inference.pdf">Functional Programming for Modular Bayesian Inference - Adam Ścibior, ICFP 2018</a></p>
<p><a href="http://www.cs.ox.ac.uk/people/hongseok.yang/paper/ifl16-full.pdf">Design and Implementation of Probabilistic Programming Language Anglican - David Tolpin, Jan-Willem van de Meent, Hongseok Yang, Frank Wood, IFL 2016</a></p>
<p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576406&amp;casa_token=ykFuETQWfDQAAAAA:yUjdDPPjS_Vpf25HewgDWzpUtE6w7jBTHCpvMeFbXf4fx7y6Jk_lwlEJfCUHJhWgZdtutQ4xSeg&amp;tag=1">Semantics for probabilistic programming: higher-order functions, continuous distributions, and soft constraints, Sam Staton, Hongseok Yang, Frank Wood, LICS 2016</a></p>
<p><a href="http://proceedings.mlr.press/v38/vandemeent15.pdf">Particle Gibbs with Ancestor Sampling for Probabilistic Programs - Jan-Willem van de Meent, Hongseok Yang, Vikash Mansinghka, Frank Wood, AISTATS 2015</a></p>
<p><a href="https://arxiv.org/pdf/1507.00996.pdf">A New Approach to Probabilistic Programming Inference (Particle MCMC) - Frank Wood, Jan-Willem van de Meent, Vikash Mansinghka, AISTATS 2014</a></p>
<h5 id="embedded-probabilistic-programming---oleg-kiselyov-ifip-2009">Embedded Probabilistic Programming - Oleg Kiselyov, IFIP 2009</h5>
<p>Two general techniques for implementing a DSL with less overhead are the <em>finally-tagless</em> (shallow) embedding of object programs, and the <em>direct-style</em> representation of side effects. They use these techniques to build a DSL for probabilistic programming, embedded as an ordinary OCalm library, and represent probability distributions as ordinary OCaml programs. They use delimited continuations to reify probabilistic programs as lazy search trees, which inference algorithms may traverse without imposing overhead on deterministic parts of a model. Inference algorithms can be easily embedded in probabilistic programs themselves.</p>
<p>They aim to build a DSL for probability distributions. A fundamental and popular way to represent a probability distribution is as a graphical model (a Bayesian network) whose nodes represent random variables and edges indicate conditional dependencies. However graphical models do not scale well to real problems involving thousands or more of random variables and dependencies.</p>
<p>It helps to embed a language of probability distributions in a host language such as Haskell - the embedded language is called  a toolkit for probabilistic reasoning, because it is structured as a library of data types of graphical models and random variables along with inference procedures that operate on them. Similarly, distributions can be represented and reasoned about in a logic using formulas that talk about probabilities. However, a toolkit defines its own data types; e.g. random integers are distinct from regular integers, and cannot be added using the addition operation of the host language.</p>
<p>The main drawback of a standalone probabilistic language is that it can&rsquo;t rely on the infrastructure of an existing host language. In contrast an embedded probabilistic language can piggyback on its host language&rsquo;s compilers to remove some interpretive overhead.</p>
<p><strong>Their Approach: A Very Shallow Embedding</strong></p>
<p>They combine the advantages of embedded and standalone probabilistic languages by embedding a language of probabilistic distributions into a general-purpose language in a <em>very shallow</em> way. That is, probabilistic functions are embedded as host-language functions, calls to them are embedded as host function calls, and random integers can be added using the addition operation of the host language.</p>
<p><strong>Contributions</strong></p>
<p>The paper describes their design of a practical DSL for probabilistic programming, by a novel combination of two existing techniques for eliminating notational and interpretive overhead in embedded languages, using OCaml:</p>
<ol>
<li>The direct-style representation of side effects using <em>delimited control operators</em> lets us reify a probabilistic program as a weighted search tree.</li>
<li>The <em>finally-tagless</em> embedding of object programs using <em>combinator functions</em> allows multiple inference algorithms to operate on the same model without the run-time overhead of tagging values with their types.
They apply these general techniques to probabilistic programming and demonstrate how they make embedded DSL programs faster to run and easier to write.</li>
</ol>
<p>Then, they show how to implement interpreters for our language that perform exact and approximate inference efficiently. Specifically:</p>
<ol>
<li>They implement <em>variable elimination</em>, an existing algorithm for exact inference.</li>
<li>They develop <em>importance sampling</em>, a general algorithm for approximate inference.</li>
<li>They support <em>lazy evaluation</em> in probabilistic programs.</li>
<li>Users of the library are free to implement their own inference algorithms.</li>
</ol>
<h5 id="functional-programming-for-modular-bayesian-inference---adam-scibior-icfp-2018">Functional Programming for Modular Bayesian Inference - Adam Scibior, ICFP 2018</h5>
<p>They present an architectural design of a library for Bayesian modelling and inference in modern functional programming languages. The novel aspect of their approach are modular implementations of existing inference algorithms. Their design relies on three inherently functional features:</p>
<ol>
<li>Higher-order functions</li>
<li>Inductive data-types</li>
<li>Support for type-classes or an expressive module system</li>
</ol>
<p>In this architecture, they use the following core abstractions:</p>
<ol>
<li>Inference representations</li>
<li>Inference transformations</li>
<li>Inference representation transformers</li>
</ol>
<p>They then implement concrete instances of these abstractions for particle filters and Metropolis-Hastings samplers, which form the basic building blocks of their library. By composing these building blocks, they obtain state-of-the-art inference algorithms.</p>
<p><strong>Existing Problems They Engage With</strong></p>
<ul>
<li>Approximate Bayesian inference deals with approximations to the model evidence and posterior distribution. Traditionally, such inference is done by hand: the descriptions of the prior and likelihood and constructed manually, the equations of the inference algorithm are derived with pen and paper, and implemented as a module of the intended application.</li>
</ul>
<p>In an attempt to partially automate this process, many libraries automatically derive selected inference algorithms from a suitable intermediate representation of the model. For example, PyMC is a python module that implements Bayesian statistical models and fits them with inference algorithms such as Markov chain Monte Carlo. (These are eDSLs)</p>
<p>To relieve users from the burden of manually constructing the intermediate representation, probabilistic programming systems such as Stan provide a special-purpose modelling language which is human-readable, where their compiler automatically generates the required simulations that approximate the model evidence or sample predictions from the posterior distribution. (These are non-embedded DSLs). The problem with non-embedded DSLs are that, while users express their models as probabilistic programs, the expressive power of the languages they use is limited, and the inference process cannot be directly incorporated into larger applications, which resort to external, file-based communication.</p>
<ul>
<li>One of the goals of probabilistic programming is to separate probabilistic programming is to separate probabilistic modelling from inference. The idea is that domain experts can specify probabilistic models according to their knowledge of the underlying process, and then an automated inference engine makes probabilistic inferences using this model.</li>
</ul>
<p><strong>Approach &amp; Contributions</strong></p>
<p>They describe a Haskell library constituting a probabilistic programming system that extends an existing language with probabilistic effects. It provides a monadic typeclass with probabilistic effects that can be used to construct probabilistic programs using arbitrary pure Haskell code.</p>
<p>Their high-level view of Bayesian inference is:</p>
<ul>
<li>We have a model, containing both sampling and conditioning operations, written by the user in a probabilistic programming language.</li>
<li>We transform the model into a probabilistic program, the &ldquo;sampler&rdquo;, containing only sampling operations. While the model is non-executable due to the conditioning operations, the sampler is executable.</li>
<li>We can therefore run the sampler, and with some post-processing, approximate the posterior distribution of the original model.</li>
</ul>
<p>The main novelty in the approach is decomposing the inference step (of converting the model into a sampler) into a sequence of intermediate steps; these intermediate steps consist of inference-specific transformations between inference-specific representations.</p>
<p>Their library provides such inference representations and inference transformers that manipulate these representations. Users can then define custom intermediate representations by composing transformers to obtain inference transformer stacks.</p>
<p>They express the building blocks for inference algorithms in Haskell, and distinguish three types of basic building blocks:</p>
<ol>
<li>Inference representations (data structures representing distributions), expressed as type-classes. There are three separate type-classes: the sampling representation <code>MonadSample</code>, the conditioning representation <code>MonadCond</code>, and the sampling and conditioning representation <code>MonadInfer</code>.</li>
<li>Inference transformations, mappings between inference representations.</li>
<li>Inference transformers, compositional building blocks of inference representations, expressed as monad transformers.</li>
</ol>
<p>They then show how to compose these building blocks to obtain advanced inference algorithms.</p>
<h5 id="probabilistic-programming-language-and-its-incremental-evaluation-hakaru---oleg-kiselyov-2016">Probabilistic Programming Language and its Incremental Evaluation (Hakaru) - Oleg Kiselyov, 2016</h5>
<p>This describes the probabilistic programming language</p>
<div class="edit-meta">
Last updated on 13 Nov 2020


<br>
Published on 13 Nov 2020
<br></div><nav class="pagination"><a class="nav nav-prev" href="https://probabilistic-effects.github.io/research/approaches-for-monad-bayes/" title="Potential Approaches to Improving Monad Bayes"><i class="fas fa-arrow-left" aria-hidden="true"></i> Prev - Potential Approaches to Improving Monad Bayes</a>
<a class="nav nav-next" href="https://probabilistic-effects.github.io/research/effects-for-less/" title="Effects for Less">Next - Effects for Less <i class="fas fa-arrow-right" aria-hidden="true"></i></a>
</nav><footer><p class="powered">Powered by <a href="https://gohugo.io">Hugo</a>. Theme by <a href="https://themes.gohugo.io/hugo-theme-techdoc/">TechDoc</a>. Designed by <a href="https://github.com/thingsym/hugo-theme-techdoc">Thingsym</a>.</p>
</footer>
</main>
<div class="sidebar">

<nav class="open-menu">
<ul>
<li class=""><a href="https://probabilistic-effects.github.io/">Home</a></li>

<li class=""><a href="https://probabilistic-effects.github.io/activity/">Activity</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/activity/cpsing-monad-bayes/">CPSing Monad Bayes</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/activity/inlining-monad-bayes/">Inlining Monad Bayes</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/papers/">Papers</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/papers/asymptotic-improvement/">Asymptotic Improvement of Computations over Free Monads</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/papers/anglican/">Design and Implementation of Probabilistic Programming Language Anglican</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/papers/faster-coroutine-pipelines/">Faster Coroutine Pipelines</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/papers/freer-monads/">Freer Monads, More Extensible Effects</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/papers/fusion-for-free/">Fusion for Free</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/papers/probabilistic-programming/">Introduction To Probabilistic Programming</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/papers/lightweight-implementations-prob-languages/">Lightweight Implementations of Probabilistic Programming Languages</a></li>
</ul>
  
</li>

<li class="parent"><a href="https://probabilistic-effects.github.io/research/">Research</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/research/research-journal/">Research Journal</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/approaches-for-monad-bayes/">Potential Approaches to Improving Monad Bayes</a></li>
<li class="active"><a href="https://probabilistic-effects.github.io/research/probabilistic-design/">Probabilistic Language Design</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/effects-for-less/">Effects for Less</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/literature-review/">Literature Review</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/parsley-case-study/">Case Study: Optimising Parsley</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/optimising-core/">Optimising Core</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/">Monad Bayes</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/inference-transformers/">Inference Transformers</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/pmmh-hmm/">Implementing HMM Simulation and Inference (using PMMH)</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/documentation/">Documentation</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/conditioning-scoring/">How Conditioning and Scoring Works</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/tooling/">Tooling</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/tooling/cabal/">Cabal Projects</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/">Benchmarking</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/benchmark-log/">Benchmark Log</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/benchmarking-profiling/">How to Benchmark and Profile</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/monad-bayes-components/">Relevant Components of Monad Bayes for Profiling</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/background/">Background</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/background/embedding/">Embedding DSLs</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/staging/">Staging</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/smc-pmmh/">SMC and PMMH</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/handrolling/">Handrolling Monad Transformer Stacks</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/mtl/">MTL</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/mcmc-mh/">MCMC and MH</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/markov-chain/">Markov Chains</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/hidden-markov-model/">Hidden Markov Model</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/delimited-continuations/">Delimited Continuations</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/haskell-core/">Haskell Core</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/inlining/">Inlining</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/specialisation/">Specialisation</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/bayesian/">Bayesian</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/concurrency/">Concurrency</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/continuations/">Continuations</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/coroutines/">Coroutines</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/monad-transformers/"></a></li>
</ul>
  
</li>
</ul>
</nav>



<div class="sidebar-footer"></div>
</div>

</div><a href="#" id="backtothetop-fixed" class="backtothetop"
 data-backtothetop-duration="600"
 data-backtothetop-easing="easeOutQuart"
 data-backtothetop-fixed-fadeIn="1000"
 data-backtothetop-fixed-fadeOut="1000"
 data-backtothetop-fixed-bottom="10"
 data-backtothetop-fixed-right="20">
<span class="fa-layers fa-fw">
<i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i>
</span></a>
</div>
</body>
</html>
