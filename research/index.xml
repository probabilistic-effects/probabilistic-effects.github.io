<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research on Probabilistic Effects.  λθ</title>
    <link>https://probabilistic-effects.github.io/research/</link>
    <description>Recent content in Research on Probabilistic Effects.  λθ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Nov 2020 13:52:51 +0000</lastBuildDate><atom:link href="https://probabilistic-effects.github.io/research/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Research Journal</title>
      <link>https://probabilistic-effects.github.io/research/research-journal/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:57 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/research-journal/</guid>
      <description>Addressing 1: TraceT [Int, Int] Addressing 2: Adding fresh addresses to all expressions during compile time, and appending them during evaluation run time for increased call stack depth - i don&amp;rsquo;t think this will work during evaluation - if we continue appending addresses for every function call, then the addresses of sample statements are affecting by the entire preceding call stack. Addressing 3: Addressing all sample statements during compile time, and indexing them by number of occurrences during evaluation run time (anglican approach) Addressing 4: Using stable names to provide addresses during eval time, and appending them as well during call stack depth  Activity (MN)</description>
    </item>
    
    <item>
      <title>Potential Approaches to Improving Monad Bayes</title>
      <link>https://probabilistic-effects.github.io/research/approaches-for-monad-bayes/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/approaches-for-monad-bayes/</guid>
      <description>Possible approaches to optimising effect systems:
 Different effects system - taking a look at the core effect library as a whole Different concrete transformers - the effects aren’t disappearing when using monad transformers  Effects for Less (Eff library) - Alexis King (Delimited continuations approach)   Staging  Multi-stage Programs In Context - Matthew Pickering, Nicolas Wu, Jamie Willis Selective Staged Parser Combinators - Jamie Willis, Nicolas Wu, Matthew Pickering (optimising parser combinators with staging)   Codensity transformations  Csongor used the codensity transform in his generic deriving paper   Tagless final style (optimises mtl style?</description>
    </item>
    
    <item>
      <title>Probabilistic Language Design</title>
      <link>https://probabilistic-effects.github.io/research/probabilistic-design/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/probabilistic-design/</guid>
      <description>Relevant Existing Probabilistic Programming Libraries/Languages
        Probabilistic Language Design
The Design and Implementation of Probabilistic Programming Languages (Learning Resource) - Noah D. Goodman and Andreas Stuhlmüller
Usability of Probabilistic Programming Languages
Embedded Domain-Specific Languages for Probabilistic Programming - Oleg Kiselyov&amp;rsquo;s Page
 Probabilistic Programming Language and its Incremental Evaluation (Hakaru10, Graphical Models) - Oleg Kiselyov, 2016 Probabilistic inference by program transformation in Hakaru - Praveen Narayanan, Chung-chieh Shan, 2016 Embedded Probabilistic Programming (Hansei) - Oleg Kiselyov, IFIP 2009  Functional probabilistic programming for scalable Bayesian modelling - Jonathan Law, Darren J.</description>
    </item>
    
    <item>
      <title>Effects for Less</title>
      <link>https://probabilistic-effects.github.io/research/effects-for-less/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:31 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/effects-for-less/</guid>
      <description>Table of Contents  Summary Thoughts Benchmarking  Summary of Alexis King - focusing on benchmarks
Summary  Real world benchmarks make it difficult to isolate costs Microbenchmarks often seen as synthetic Microbenchmarks need to make sure you&amp;rsquo;re measuring the right thing Might not have broad scope. Effects systems make real world programs hard to benchmark Effects systems tend to have small operations that do not take a significant amount of time Splitting in modules slows stuff down Compiler optimisations lead to cross module slowdowns Free monad libraries, by constructing trees, obscures the program structure to the optimiser preventing inlining.</description>
    </item>
    
    <item>
      <title>Literature Review</title>
      <link>https://probabilistic-effects.github.io/research/literature-review/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:31 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/literature-review/</guid>
      <description>‣ Relevant Existing Probabilistic Programming Libraries/Languages      ‣ Papers Probabilistic Programming
 An Introduction To Probabilistic Programming Lightweight Implementations of Probabilistic Programming Languages Via Transformational Compilation - David Wingate, Andreas Stuhlmüller, and Noah Goodman. 2011. Practical Probabilistic Programming with Monads - Ścibior, Adam, Zoubin Ghahramani, and Andrew D. Gordon. Proceedings of the 2015 ACM SIGPLAN Symposium on Haskell. 2015. Denotational Validation of Higher-Order Bayesian Inference - Ścibior, Adam.</description>
    </item>
    
    <item>
      <title>Case Study: Optimising Parsley</title>
      <link>https://probabilistic-effects.github.io/research/parsley-case-study/</link>
      <pubDate>Fri, 13 Nov 2020 13:49:05 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/parsley-case-study/</guid>
      <description>The best way to understand why a profiling report outputs certain performance metrics (for Haskell) is to dive into the actual core itself, which is what the surface-level Haskell code compiles down into.
Usually, if one is confused about something in the core, it is best to compare it with the original program.
regTest :: Parser Int regTest = newRegister_ (code 7) (\r -&amp;gt; modify_ r makeQ (succ @Int) [||succ @Int||]) *&amp;gt; (let g = get r in g *&amp;gt; g)) This makes a new register, which in this context would be an STRef, containing 7; it then modifies it with +1, and afterwards it gets the value out twice, and returns it the second time.</description>
    </item>
    
    <item>
      <title>Optimising Core</title>
      <link>https://probabilistic-effects.github.io/research/optimising-core/</link>
      <pubDate>Fri, 13 Nov 2020 13:40:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/optimising-core/</guid>
      <description>These are some organised notes on optimising core, summarised from other pages.
1. Dumping core &amp;amp; enabling optimisations   To inspect the core (in a coherent manner), we can add the following to either our package.yaml file (when using stack):
ghc-options: - dump-core dependencies: - -fplugin=DumpCore or our .cabal file (when using cabal):
build-depends: dump-core ghc-options: -fplugin-DumpCore When we build our program (stack build or ghc), this creates a folder called dump-core containing html files.</description>
    </item>
    
  </channel>
</rss>
