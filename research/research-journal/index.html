<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<title>Research Journal - Probabilistic Effects.  λθ</title>
<meta name="generator" content="Hugo 0.78.2" />
<link href="https://probabilistic-effects.github.io//index.xml" rel="alternate" type="application/rss+xml">
<link rel="canonical" href="https://probabilistic-effects.github.io/research/research-journal/">
<link rel="stylesheet" href="https://probabilistic-effects.github.io/css/theme.min.css">
<script src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>
<link rel="stylesheet" href="https://probabilistic-effects.github.io/css/chroma.min.css">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script>
<script src="https://probabilistic-effects.github.io/js/bundle.js"></script><style>
:root {}
</style>
<meta property="og:title" content="Research Journal" />
<meta property="og:description" content="• Scrum Meeting 1 (MW &#43; SF &#43; MN) 03/11/2020
  Can the inference monad transformer stack of a program be inferred/fixed at compile time?
  Identifying smaller goals and intermediate research ideas and what is valuable to do:
 What&rsquo;s the line between papers and a very good blog post? (new things are papers) How can research/observations across monad-bayes be generalised? It is possible to do an empirical evaluation and target software dev audiences Programming languages field lacks proper evaluations; it is possible to question existing &ldquo;folklore&rdquo; with new observed results&quot; It is important to know what the benchmarking tool can and can&rsquo;t do - when experimenting we must always ask what can the tool do for me." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://probabilistic-effects.github.io/research/research-journal/" />
<meta property="article:published_time" content="2020-11-13T14:05:57+00:00" />
<meta property="article:modified_time" content="2020-11-13T14:05:57+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Research Journal"/>
<meta name="twitter:description" content="• Scrum Meeting 1 (MW &#43; SF &#43; MN) 03/11/2020
  Can the inference monad transformer stack of a program be inferred/fixed at compile time?
  Identifying smaller goals and intermediate research ideas and what is valuable to do:
 What&rsquo;s the line between papers and a very good blog post? (new things are papers) How can research/observations across monad-bayes be generalised? It is possible to do an empirical evaluation and target software dev audiences Programming languages field lacks proper evaluations; it is possible to question existing &ldquo;folklore&rdquo; with new observed results&quot; It is important to know what the benchmarking tool can and can&rsquo;t do - when experimenting we must always ask what can the tool do for me."/>
<meta itemprop="name" content="Research Journal">
<meta itemprop="description" content="• Scrum Meeting 1 (MW &#43; SF &#43; MN) 03/11/2020
  Can the inference monad transformer stack of a program be inferred/fixed at compile time?
  Identifying smaller goals and intermediate research ideas and what is valuable to do:
 What&rsquo;s the line between papers and a very good blog post? (new things are papers) How can research/observations across monad-bayes be generalised? It is possible to do an empirical evaluation and target software dev audiences Programming languages field lacks proper evaluations; it is possible to question existing &ldquo;folklore&rdquo; with new observed results&quot; It is important to know what the benchmarking tool can and can&rsquo;t do - when experimenting we must always ask what can the tool do for me.">
<meta itemprop="datePublished" content="2020-11-13T14:05:57+00:00" />
<meta itemprop="dateModified" content="2020-11-13T14:05:57+00:00" />
<meta itemprop="wordCount" content="2593">



<meta itemprop="keywords" content="" />
</head>
<body><div class="container"><header>
<h1>Probabilistic Effects.  λθ</h1>
</header>

<div class="content-container">
<main><h1>Research Journal</h1>
<p><strong>• Scrum Meeting 1 (MW + SF + MN)</strong>     <em>03/11/2020</em></p>
<ul>
<li>
<p>Can the inference monad transformer stack of a program be inferred/fixed at compile time?</p>
</li>
<li>
<p>Identifying smaller goals and intermediate research ideas and what is valuable to do:</p>
<ul>
<li>What&rsquo;s the line between papers and a very good blog post? (new things are papers)</li>
<li>How can research/observations across monad-bayes be generalised?</li>
<li>It is possible to do an empirical evaluation and target software dev audiences</li>
<li>Programming languages field lacks proper evaluations; it is possible to question existing &ldquo;folklore&rdquo; with new observed results&quot;</li>
<li>It is important to know what the benchmarking tool can and can&rsquo;t do - when experimenting we must always ask what can the tool do for me. Goal is guided by what you can measure.</li>
</ul>
</li>
</ul>
<p><strong>• Scrum Meeting 2 (MW + SF + MN)</strong>     <em>10/11/2020</em></p>
<ul>
<li>
<p>Meeting with AZ</p>
</li>
<li>
<p>Visualiser set up for the profiling info</p>
</li>
<li>
<p>Reading up on three different effect system optimisation approaches inc:</p>
<ul>
<li>Alexis King - delimited continuations and the Cont monad.</li>
<li>Codensity transformations (Csongor used this in his generic deriving paper)</li>
<li>Staging (perhaps see JW&rsquo;s staged parser combinator paper)</li>
<li>Tagless final style
<ul>
<li>SF has read this paper. Here are their notes:
Typed tagless final style if a good approach from embedding a DSL Pros: Types are preserved; Efficient; Doesn&rsquo;t get stuck; Can express pattern matching and non-compositional things; Extensible; The heart of this style is adding a type param polymorphism and parameterisation.
NW: “it is a precursor to algebraic effects”. Tagless final style and algebraic effects are just implementations within a broader field, it would be better to understand the general specification of how to embed properly. Following NW&rsquo;s advice I will now read a few papers that give me a broader insight into the field of algebraic effects, to get the more general view, instead of focusing on a specific implementation.
Suggested papers: &ldquo;Handlers of Algebraic Effects&rdquo;, &ldquo;Programming and Reasoning with Algebraic Effects and Effect Handlers&rdquo;, &ldquo;From Theory to Practice of Algebraic Effects and Handlers&rdquo; (SF started reading the first, but found it a bit hard due to lack of knowledge in that area).</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Plan = Current direction is to implement using three different effect system approaches and then evaluate; hopefully something interesting will come out of this.</p>
</li>
<li>
<p>Suggestion (MW): Just use a minimal calculus for experiments, and then have Monad Bayes as the big example.</p>
</li>
<li>
<p>Suggestion (MW): Evaluate whether the embedding of Monad Bayes' DSL is shallow/deep and how this affects performance; shallow embeddings are naturally less efficient than deep embeddings.</p>
</li>
<li>
<p>Weekly meetings set up between MN &amp; AZ to keep discussions and progress churning. Currently reading with purpose and writing up notes, while also doing some coding/profiling and discussing each week. progressing well.</p>
</li>
</ul>
<p><strong>• Slack (MN + JW)</strong>     <em>11/11/2020</em></p>
<ul>
<li>
<p>Does there exist a good paper/resource on how staging can be used to optimise effect systems in general?</p>
</li>
<li>
<p>Nope, it hasn&rsquo;t been done in general yet - there are people (NW) working on this. Additionally, the staged SOP and the Parsley paper both provide meaningful nuggets about how to use staging for optimisation.</p>
</li>
</ul>
<p><strong>• Slack (MN + NW)</strong>     <em>11/11/2020</em></p>
<ul>
<li>Touched base with NW on project status:
<ul>
<li>Current idea is take the monad-bayes (which is a slow probabilistic programming library in Haskell) and implement a similar idea using different effect systems to understand what happens and why to the performance - hopefully something interesting will come out of it
&amp; asked about staging on optimising effect systems (as a potential direction for improving monad-bayes).</li>
<li>Sounds promising</li>
</ul>
</li>
<li>Asked about existing papers/resources about using staging to optimise effect systems in general (with the intention to apply as a possible direction towards improving monad-bayes)
<ul>
<li>NW is working on such a paper; it is most likely a natural combination of the work on staging with MP and the Fusion for Free work.</li>
</ul>
</li>
<li>Need to set up meeting with NW when a valuable discussion is to be had about the current state of the project. We are still currently invested in reading.</li>
<li>Suggested related paper: <a href="https://dl.acm.org/doi/pdf/10.1145/3408975">https://dl.acm.org/doi/pdf/10.1145/3408975</a></li>
</ul>
<p><strong>• Discussion following conversation with NW (MH + AZ)</strong>     <em>11/11/2020</em></p>
<ul>
<li>
<p>That <a href="https://dl.acm.org/doi/pdf/10.1145/3408975">link</a> looks more like actually writing an effect system, not using an existing one. There is a slight reticence to get involved in actually creating effect systems. However that direction may potentially be a good place to go in the future; a natural path after using all of these effect systems (of interest) would probably be developing an effect system. AZ not particularly interested in this at the moment, but could be for MN.</p>
</li>
<li>
<p>Fusion for free with staging seems like a pretty obviously successful idea. AZ has a vague intuition for how that might work, but not confident enough to see the path forward there (w.r.t what NW is working on - not related to probabilistic-effects)</p>
</li>
<li>
<p>Intuition is that fusion for free is relevant to probabilistic-effects, but Alexis King&rsquo;s Eff library is the best bet.</p>
</li>
<li>
<p>With respect to MW&rsquo;s suggestion on a restricted calculus, this needs some thought, but is likely a good/possible direction.</p>
</li>
<li>
<p>The <code>Eff</code> library exists as a fork of GHC - we can just use that fork with the patch and the library. <code>Eff</code> is quite early stage but it looks stable enough for us to use. This is a probably the best starting point. We also have the <code>monad-bayes</code> the library so it shouldn&rsquo;t be a huge step re-implementing, and if it works, it would obviously be the best suggestion. Why rewrite everything in a complex way when you can just move to the same system but better?</p>
</li>
<li>
<p>One of the next best (computationally-related) goals would be to work out how to get Alexis King&rsquo;s patch and library working. This looks like the patch branch: <a href="https://github.com/lexi-lambda/ghc-proposals/tree/delimited-continuation-primops">https://github.com/lexi-lambda/ghc-proposals/tree/delimited-continuation-primops</a></p>
</li>
<li>
<p>How do we turn this into research, rather than simply an application of a different effect system to an existing library?</p>
</li>
<li>
<p>The research aspect would be comparing the different methods in my opinion. If we&rsquo;re looking for new <em>things</em>, then maybe the stuff NW is working on? It is possible that <em>just</em> staging it or <em>just</em> using codensity/fusion stuff would count as novel research, given that JW has a paper on staging parsley. Additionally, we believe that case studies/methodology papers like &ldquo;how to optimise something built on an effect system&rdquo; are important research, however sometimes academia can be a bit snooty.</p>
</li>
<li>
<p>If we think a case study methodology is too risky (out of a fear of some kind of lack of appreciation) maybe just staging or doing fusion would be best as that would be novel. Staging is just more involved and would require more novel insight / the path is less charted, whereas <code>eff</code> would likely be easier to reimplement <code>monad-bayes</code> with essentially. If we feel more inclined to take a case study approach initially, going to <code>eff</code> would be the best first move. Either option is plausible, but we&rsquo;ll end up doing <code>eff</code> either way as it&rsquo;s the best bet to actually make it faster.
Additionally, we&rsquo;ll be able to reach a milestone faster and feel a bit better about taking other approaches.</p>
</li>
<li>
<p>Optimistically, we could get the <code>eff</code> content done by the end of the year or early January.</p>
</li>
</ul>
<p><strong>Meeting (MN + AZ)</strong>     <em>12/11/2020</em></p>
<p>Analysing profile report on PMMH inference for a HMM:</p>
<p><img src="https://i.ibb.co/6mv24Cp/pmmh-prof.png" alt=""></p>
<p>The key points of interest are:</p>
<ul>
<li>
<p>The <code>(&gt;&gt;=)</code> operation which occurs in <code>Population.hs</code>, accounting for 35% of the total runtime. The source line responsible for this is found in the typeclass derivations of the <code>Population</code> newtype, namely the deriving of the <code>Monad</code> class.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#75715e">-- | A collection of weighted samples, or particles.</span>
<span style="color:#66d9ef">newtype</span> <span style="color:#66d9ef">Population</span> m a <span style="color:#f92672">=</span> <span style="color:#66d9ef">Population</span> (<span style="color:#66d9ef">Weighted</span> (<span style="color:#66d9ef">ListT</span> m) a)
  <span style="color:#66d9ef">deriving</span> (<span style="color:#66d9ef">Functor</span>, <span style="color:#66d9ef">Applicative</span>, <span style="color:#66d9ef">Monad</span>, <span style="color:#66d9ef">MonadIO</span>, <span style="color:#66d9ef">MonadSample</span>, <span style="color:#66d9ef">MonadCond</span>, <span style="color:#66d9ef">MonadInfer</span>)
</code></pre></div></li>
<li>
<p>The <code>liftA2</code> operation and the <code>pure</code> operation which both occur in <code>Weighted.hs</code>, accounting for 11.9% and 7.9% of the total runtime respectively. The source line responsible for this is found in the typeclass derivations of the <code>Weighted</code> newtype, namely the deriving of the <code>Applicative</code> class.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#75715e">-- | Execute the program using the prior distribution, while accumulating likelihood.</span>
<span style="color:#66d9ef">newtype</span> <span style="color:#66d9ef">Weighted</span> m a <span style="color:#f92672">=</span> <span style="color:#66d9ef">Weighted</span> (<span style="color:#66d9ef">StateT</span> (<span style="color:#66d9ef">Log</span> <span style="color:#66d9ef">Double</span>) m a)
  <span style="color:#75715e">-- StateT is more efficient than WriterT</span>
  <span style="color:#66d9ef">deriving</span> (<span style="color:#66d9ef">Functor</span>, <span style="color:#66d9ef">Applicative</span>, <span style="color:#66d9ef">Monad</span>, <span style="color:#66d9ef">MonadIO</span>, <span style="color:#66d9ef">MonadTrans</span>, <span style="color:#66d9ef">MonadSample</span>)
</code></pre></div></li>
</ul>
<p>These overheads are associated with the inference representations/transformer stack which <code>monad-bayes</code> uses, as opposed to time spent on numerical computation such as with the <code>bernoulli</code> function.</p>
<p>This prompts the questions:</p>
<ul>
<li>What definitions of <code>(&gt;&gt;=)</code>, <code>liftA2</code>, and <code>pure</code> are generated as a result of using <code>deriving</code>, and why are these inefficient for our case?</li>
</ul>
<p><strong>Meeting (MN + AZ + JW)</strong>     <em>13/11/2020</em></p>
<p>Following the previous meeting, this was an extremely helpful discussion (with JW) about how to proceed given the profiler report. Content from this meeting is fully elaborated on <a href="./../../benchmarking/haskell-core">here</a>.
Briefly summarised, we were introduced to:</p>
<ul>
<li>The ghc-option/dependency <code>dump-core</code> as a means of finding out what core Haskell code is generated from surface-level Haskell code</li>
<li>How to understand various core-level syntax</li>
<li>The general workflow needed when investigating/identifying inefficiencies in programs</li>
<li>Common problematic fragments of code to look out for in the core program.</li>
</ul>
<p>Thoughts:</p>
<ul>
<li>There is definitely a place for a good tutorial paper on how to do all of this (understanding Haskell core, the relationship between surface-level code and core, and identifying possible optimisations). If we pay strong attention to what we do in the next few weeks and write up our process, this would be a good contribution towards the general question of how to optimise a Haskell program. What we&rsquo;re about to do is what a lot of people do without any resources. A quick outline of such a paper would be to: 1) emphasize the process of profiling your code dumping the core of the highly used functions, and 2) distill what it is one should looking out for in the core. This could be a good Haskell symposium paper.</li>
</ul>
<p>From this, our next targets are:</p>
<ul>
<li>Compile <code>monad-bayes</code> with the <code>dump-core</code> plugin on, and invest time in figuring out where performance issues lie in the core code.</li>
<li>Writing the hand-rolled versions of instances for all the inference transformers of <code>monad-bayes</code> (there&rsquo;s an incomplete page <a href="./../../background/performance-w-monads">here</a> on unrolling monad transformers), and compare the core for both the hand-rolled version and the <code>monad-bayes</code> library itself, and identify what is slow.</li>
<li>Look for some resources (e.g. tutorials or talks) on understanding core.</li>
<li>To record/write up our workflow and stream of consciousness as we progress on understanding how to optimise <code>monad-bayes</code> by using core.</li>
<li>Have a work session during weekend on 21/11/2020</li>
</ul>
<p><strong>Debugging - Getting dump-core to work (AZ + MN)</strong>     <em>16/11/2020</em></p>
<ul>
<li>
<p>Adding the ghc-option and dependencies for <code>dump-core</code> in <code>package.yaml</code> gives us the following error:</p>
<p><img src="https://i.ibb.co/dks5SZ8/dump-core-1.png" alt=""></p>
</li>
<li>
<p>From this, adding the extra dependency <code>dump-core-0.1.3.2</code> in <code>stack.yaml</code> gives us the below error. This is a resolver error i.e. stack can not resolve the constraints of the packages. Stack works by collecting bunches of packages that work together and calls them an lts (long-time-support). The constraint is generated by <code>dump-core</code>, which says that the version of <code>base</code> that our stack project uses does not match the version of <code>base</code> that <code>dump-core</code> uses, i.e. we need a version of <code>base</code> from <code>&gt;=4.9 &amp; &lt; 4.13</code>, and the most recent version satisfying this constraint is <code>4.12.0</code>.</p>
<p><img src="https://i.ibb.co/S70dkJs/dump-core-3.png" alt=""></p>
</li>
<li>
<p>Looking at the various <code>lts</code> versions, the resolver version <code>lts-14.1</code> supports <code>base</code> version <code>4.12.0</code>, which uses <code>GHC</code> version <code>8.6.5</code>.</p>
<p><img src="https://i.ibb.co/5Y2L4sV/dump-core-5.png" alt=""></p>
</li>
<li>
<p>Setting <code>resolver</code> to <code>lts-14.1</code> then gives the following extra dependency error:</p>
<p><img src="https://i.ibb.co/tpdc1x6/dump-core-6.png" alt=""></p>
</li>
<li>
<p>Introducing these extra dependencies then finally solves the problem:</p>
<p><img src="https://i.ibb.co/54696LK/dump-core-4.png" alt=""></p>
</li>
<li>
<p>Running <code>stack build</code> now generates a folder called <code>dump-core</code>, containing <code>html</code> files for visualisations of the core Haskell code generated from our program.</p>
<p><img src="https://i.ibb.co/9sqQwzG/dump-core-7.png" alt=""></p>
</li>
</ul>
<p><strong>Debugging - Getting dump-core to generate the desired files (MN)</strong>     <em>18/11/2020</em></p>
<ul>
<li>
<p>Given the below configuration of <code>package.yaml</code>, cabal does not generate any executables for the <code>library</code> fields, so running <code>stack build</code> with <code>dump-core</code> will unhelpfully generate a <code>Paths_&lt;package_name&gt;.html</code> file, part of which represents our code found in the <code>src</code> directory.</p>
<p><img src="https://i.ibb.co/DGFsDPT/dump-core-1-0.png" alt=""></p>
</li>
<li>
<p>In order to generate core for desired files in directory <code>src</code>, we need to either:</p>
<ol>
<li>Move <code>Main.hs</code> to <code>src</code> and change the <code>source-dirs</code> field under <code>executables</code> from <code>app</code> to <code>src</code></li>
<li>Add <code>src</code> to the <code>source-dirs</code> field under <code>executables</code>, and add the <code>dependencies</code> under <code>library</code> to the <code>dependencies</code> under <code>executables</code>.
The second option is shown below:</li>
</ol>
<p><img src="https://i.ibb.co/D16HmRt/dump-core-1-1.png" alt=""></p>
</li>
</ul>
<p><strong>Meeting (MN + AZ)</strong>     <em>19/11/2020</em></p>
<p>To do in preparation for work session on Sunday (22/11/2020):</p>
<ul>
<li>Clone <code>monad-bayes</code> and link it as a local library by placing it in the same stack project/folder as <code>probalistic-programming</code>. Then dump the core code for it.</li>
<li>Read and write up <a href="https://wiki.haskell.org/Performance/GHC#Looking_at_the_Core">tutorials</a> on core + get a gist of existing resources around optimising Haskell and what remains unexplored/unwritten about.</li>
<li>Familiarise ourselves with hand-rolling monad transformers.</li>
</ul>
<p><strong>Meeting (MN + MW + RP)</strong>     <em>19/11/2020</em></p>
<ul>
<li>It&rsquo;s useful to know if performance improves linearly/asymptotically or remains linear/asymptotic, following the first attempt at optimising <code>monad-bayes</code> e.g. by hand-rolling the inference transformers.</li>
<li>In response to the question on using <code>Eff</code>, &ldquo;how do we turn this into research, rather than simply an application of a different effect system to an existing library?&rdquo;, we can ask ourselves whether this application is straightforward. If it isn&rsquo;t straightforward, then there&rsquo;s probably a research element in it. It is definitely right to try to use what existing libraries/tools are already there. The suspicion is that, along the way, we will find something within these existing approaches that is worth researching, as there will be some problems to be addressed and changes to be made. Until we have exhausted existing options, it would be wrong to start our own. This would be a requirement from reviewers that we are not reinventing the wheel.</li>
<li><code>Eff</code> is not a mature library at all - if we were to make progress understanding and using it to reimplement the <code>monad-bayes</code> system in that setting, that would already be building towards some sort of contribution which a lot of interesting stuff is likely to come out of.
Eventually, it could maybe feed into the evolution of the <code>Eff</code> library, or similarly with <code>monad-bayes</code>. There are two or three different directions we could imagine making progress in: one is a better version of <code>monad-bayes</code> or probabilistic programming in Haskell, another is a better version of <code>Eff</code>.</li>
<li>The current direction is already definitely research/publishable somewhere, the only question is if it is ICFP etc. We&rsquo;re in a good position in the sense that we have quite an ambitious goal in mind and we have a plan with multiple paths of achieving that, but we haven&rsquo;t arrived yet because we don&rsquo;t know what we&rsquo;ll end up with. It&rsquo;s extremely likely that opportunities (for getting side-tracked onto more concrete research) will appear during this process.</li>
<li>We have atleast two concrete targets at the moment: 1) Using <code>Eff</code> to reimplement <code>monad-bayes</code> (sounds like a good thing to pursue) 2) Hand-rolling <code>monad-bayes</code> and seeing if there is some kind of asymptotic change in performance, and if there is, then we&rsquo;ve atleast identified the problem there.</li>
<li>Research almost always starts with a concrete example - once we understand it, then we can see how much we can generalise it.</li>
<li>It&rsquo;s a good sign that we are taking ideas from multiple sources, and indicates that the work is not straightforward. (Taking an idea from one paper and applying it, is quite worrying, whereas being able to show that we have taken ideas from multiple papers is promising.)</li>
<li>Good idea to collect a literature review around <code>probabilistic-effects</code> in order to have a more concrete mind-map of research directions, and organize them around how they might contribute to our research going forward.</li>
</ul>
<p><strong>Activity (MN)</strong>     <em>20/11/2020</em></p>
<ul>
<li>Added literature review.</li>
<li>Cloned <code>monad-bayes</code> as a local package to <code>probalistic-programming</code> repo and re-organized project.</li>
<li>Dumped the core of <code>monad-bayes</code>.</li>
</ul>
<div class="edit-meta">
Last updated on 13 Nov 2020


<br>
Published on 13 Nov 2020
<br></div><nav class="pagination"><a class="nav nav-prev" href="https://probabilistic-effects.github.io/research/" title="Research"><i class="fas fa-arrow-left" aria-hidden="true"></i> Prev - Research</a>
<a class="nav nav-next" href="https://probabilistic-effects.github.io/research/approaches-for-monad-bayes/" title="Potential Approaches to Improving Monad Bayes">Next - Potential Approaches to Improving Monad Bayes <i class="fas fa-arrow-right" aria-hidden="true"></i></a>
</nav><footer><p class="powered">Powered by <a href="https://gohugo.io">Hugo</a>. Theme by <a href="https://themes.gohugo.io/hugo-theme-techdoc/">TechDoc</a>. Designed by <a href="https://github.com/thingsym/hugo-theme-techdoc">Thingsym</a>.</p>
</footer>
</main>
<div class="sidebar">

<nav class="open-menu">
<ul>
<li class=""><a href="https://probabilistic-effects.github.io/">Home</a></li>

<li class="parent"><a href="https://probabilistic-effects.github.io/research/">Research</a>
  
<ul class="sub-menu">
<li class="active"><a href="https://probabilistic-effects.github.io/research/research-journal/">Research Journal</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/approaches-for-monad-bayes/">Potential Approaches to Improving Monad Bayes</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/effects-for-less/">Effects for Less - Alexis King&#39;s Talk Summary</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/literature-review/">Literature Review</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/">Monad Bayes</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/inference-transformers/">Inference Transformers</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/pmmh-hmm/">Implementing HMM Simulation and Inference (using PMMH)</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/conditioning-scoring/">How Conditioning and Scoring Works</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/">Benchmarking</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/benchmarking-profiling/">How to Benchmark and Profile</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/monad-bayes-components/">Relevant Components of Monad Bayes for Profiling</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/haskell-core/">Haskell Core</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/background/">Background</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/background/staging/">Staging</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/smc-pmmh/">SMC and PMMH</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/performance-w-monads/">Performance With Monads</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/mtl/">MTL</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/mcmc-mh/">MCMC and MH</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/markov-chain/">Markov Chains</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/hidden-markov-model/">Hidden Markov Model</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/delimited-continuations/">Delimited Continuations</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/continuations/">Continuations</a></li>
</ul>
  
</li>
</ul>
</nav>



<div class="sidebar-footer"></div>
</div>

</div><a href="#" id="backtothetop-fixed" class="backtothetop"
 data-backtothetop-duration="600"
 data-backtothetop-easing="easeOutQuart"
 data-backtothetop-fixed-fadeIn="1000"
 data-backtothetop-fixed-fadeOut="1000"
 data-backtothetop-fixed-bottom="10"
 data-backtothetop-fixed-right="20">
<span class="fa-layers fa-fw">
<i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i>
</span></a>
</div>
</body>
</html>
