<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<title>Research Journal - Probabilistic Effects.  λθ</title>
<meta name="generator" content="Hugo 0.78.2" />
<link href="https://probabilistic-effects.github.io//index.xml" rel="alternate" type="application/rss+xml">
<link rel="canonical" href="https://probabilistic-effects.github.io/research/research-journal/">
<link rel="stylesheet" href="https://probabilistic-effects.github.io/css/theme.min.css">
<script src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>
<link rel="stylesheet" href="https://probabilistic-effects.github.io/css/chroma.min.css">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script>
<script src="https://probabilistic-effects.github.io/js/bundle.js"></script><style>
:root {}
</style>
<meta property="og:title" content="Research Journal" />
<meta property="og:description" content="• Scrum Meeting 1 (MW &#43; SF &#43; MN) 03/11/2020
  Can the inference monad transformer stack of a program be inferred/fixed at compile time?
  Identifying smaller goals and intermediate research ideas and what is valuable to do:
 What&rsquo;s the line between papers and a very good blog post? (new things are papers) How can research/observations across monad-bayes be generalised? It is possible to do an empirical evaluation and target software dev audiences Programming languages field lacks proper evaluations; it is possible to question existing &ldquo;folklore&rdquo; with new observed results&quot; It is important to know what the benchmarking tool can and can&rsquo;t do - when experimenting we must always ask what can the tool do for me." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://probabilistic-effects.github.io/research/research-journal/" />
<meta property="article:published_time" content="2020-11-13T14:05:57+00:00" />
<meta property="article:modified_time" content="2020-11-13T14:05:57+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Research Journal"/>
<meta name="twitter:description" content="• Scrum Meeting 1 (MW &#43; SF &#43; MN) 03/11/2020
  Can the inference monad transformer stack of a program be inferred/fixed at compile time?
  Identifying smaller goals and intermediate research ideas and what is valuable to do:
 What&rsquo;s the line between papers and a very good blog post? (new things are papers) How can research/observations across monad-bayes be generalised? It is possible to do an empirical evaluation and target software dev audiences Programming languages field lacks proper evaluations; it is possible to question existing &ldquo;folklore&rdquo; with new observed results&quot; It is important to know what the benchmarking tool can and can&rsquo;t do - when experimenting we must always ask what can the tool do for me."/>
<meta itemprop="name" content="Research Journal">
<meta itemprop="description" content="• Scrum Meeting 1 (MW &#43; SF &#43; MN) 03/11/2020
  Can the inference monad transformer stack of a program be inferred/fixed at compile time?
  Identifying smaller goals and intermediate research ideas and what is valuable to do:
 What&rsquo;s the line between papers and a very good blog post? (new things are papers) How can research/observations across monad-bayes be generalised? It is possible to do an empirical evaluation and target software dev audiences Programming languages field lacks proper evaluations; it is possible to question existing &ldquo;folklore&rdquo; with new observed results&quot; It is important to know what the benchmarking tool can and can&rsquo;t do - when experimenting we must always ask what can the tool do for me.">
<meta itemprop="datePublished" content="2020-11-13T14:05:57+00:00" />
<meta itemprop="dateModified" content="2020-11-13T14:05:57+00:00" />
<meta itemprop="wordCount" content="3719">



<meta itemprop="keywords" content="" />
</head>
<body><div class="container"><header>
<h1>Probabilistic Effects.  λθ</h1>
</header>

<div class="content-container">
<main><h1>Research Journal</h1>
<p><strong>• Scrum Meeting 1 (MW + SF + MN)</strong>     <em>03/11/2020</em></p>
<ul>
<li>
<p>Can the inference monad transformer stack of a program be inferred/fixed at compile time?</p>
</li>
<li>
<p>Identifying smaller goals and intermediate research ideas and what is valuable to do:</p>
<ul>
<li>What&rsquo;s the line between papers and a very good blog post? (new things are papers)</li>
<li>How can research/observations across monad-bayes be generalised?</li>
<li>It is possible to do an empirical evaluation and target software dev audiences</li>
<li>Programming languages field lacks proper evaluations; it is possible to question existing &ldquo;folklore&rdquo; with new observed results&quot;</li>
<li>It is important to know what the benchmarking tool can and can&rsquo;t do - when experimenting we must always ask what can the tool do for me. Goal is guided by what you can measure.</li>
</ul>
</li>
</ul>
<p><strong>• Scrum Meeting 2 (MW + SF + MN)</strong>     <em>10/11/2020</em></p>
<ul>
<li>
<p>Meeting with AZ</p>
</li>
<li>
<p>Visualiser set up for the profiling info</p>
</li>
<li>
<p>Reading up on three different effect system optimisation approaches inc:</p>
<ul>
<li>Alexis King - delimited continuations and the Cont monad.</li>
<li>Codensity transformations (Csongor used this in his generic deriving paper)</li>
<li>Staging (perhaps see JW&rsquo;s staged parser combinator paper)</li>
<li>Tagless final style
<ul>
<li>SF has read this paper. Here are their notes:
Typed tagless final style if a good approach from embedding a DSL Pros: Types are preserved; Efficient; Doesn&rsquo;t get stuck; Can express pattern matching and non-compositional things; Extensible; The heart of this style is adding a type param polymorphism and parameterisation.
NW: “it is a precursor to algebraic effects”. Tagless final style and algebraic effects are just implementations within a broader field, it would be better to understand the general specification of how to embed properly. Following NW&rsquo;s advice I will now read a few papers that give me a broader insight into the field of algebraic effects, to get the more general view, instead of focusing on a specific implementation.
Suggested papers: &ldquo;Handlers of Algebraic Effects&rdquo;, &ldquo;Programming and Reasoning with Algebraic Effects and Effect Handlers&rdquo;, &ldquo;From Theory to Practice of Algebraic Effects and Handlers&rdquo; (SF started reading the first, but found it a bit hard due to lack of knowledge in that area).</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Plan = Current direction is to implement using three different effect system approaches and then evaluate; hopefully something interesting will come out of this.</p>
</li>
<li>
<p>Suggestion (MW): Just use a minimal calculus for experiments, and then have Monad Bayes as the big example.</p>
</li>
<li>
<p>Suggestion (MW): Evaluate whether the embedding of Monad Bayes' DSL is shallow/deep and how this affects performance; shallow embeddings are naturally less efficient than deep embeddings.</p>
</li>
<li>
<p>Weekly meetings set up between MN &amp; AZ to keep discussions and progress churning. Currently reading with purpose and writing up notes, while also doing some coding/profiling and discussing each week. progressing well.</p>
</li>
</ul>
<p><strong>• Slack (MN + JW)</strong>     <em>11/11/2020</em></p>
<ul>
<li>
<p>Does there exist a good paper/resource on how staging can be used to optimise effect systems in general?</p>
</li>
<li>
<p>Nope, it hasn&rsquo;t been done in general yet - there are people (NW) working on this. Additionally, the staged SOP and the Parsley paper both provide meaningful nuggets about how to use staging for optimisation.</p>
</li>
</ul>
<p><strong>• Slack (MN + NW)</strong>     <em>11/11/2020</em></p>
<ul>
<li>Touched base with NW on project status:
<ul>
<li>Current idea is take the monad-bayes (which is a slow probabilistic programming library in Haskell) and implement a similar idea using different effect systems to understand what happens and why to the performance - hopefully something interesting will come out of it
&amp; asked about staging on optimising effect systems (as a potential direction for improving monad-bayes).</li>
<li>Sounds promising</li>
</ul>
</li>
<li>Asked about existing papers/resources about using staging to optimise effect systems in general (with the intention to apply as a possible direction towards improving monad-bayes)
<ul>
<li>NW is working on such a paper; it is most likely a natural combination of the work on staging with MP and the Fusion for Free work.</li>
</ul>
</li>
<li>Need to set up meeting with NW when a valuable discussion is to be had about the current state of the project. We are still currently invested in reading.</li>
<li>Suggested related paper: <a href="https://dl.acm.org/doi/pdf/10.1145/3408975">https://dl.acm.org/doi/pdf/10.1145/3408975</a></li>
</ul>
<p><strong>• Discussion following conversation with NW (MH + AZ)</strong>     <em>11/11/2020</em></p>
<ul>
<li>
<p>That <a href="https://dl.acm.org/doi/pdf/10.1145/3408975">link</a> looks more like actually writing an effect system, not using an existing one. There is a slight reticence to get involved in actually creating effect systems. However that direction may potentially be a good place to go in the future; a natural path after using all of these effect systems (of interest) would probably be developing an effect system. AZ not particularly interested in this at the moment, but could be for MN.</p>
</li>
<li>
<p>Fusion for free with staging seems like a pretty obviously successful idea. AZ has a vague intuition for how that might work, but not confident enough to see the path forward there (w.r.t what NW is working on - not related to probabilistic-effects)</p>
</li>
<li>
<p>Intuition is that fusion for free is relevant to probabilistic-effects, but Alexis King&rsquo;s Eff library is the best bet.</p>
</li>
<li>
<p>With respect to MW&rsquo;s suggestion on a restricted calculus, this needs some thought, but is likely a good/possible direction.</p>
</li>
<li>
<p>The <code>Eff</code> library exists as a fork of GHC - we can just use that fork with the patch and the library. <code>Eff</code> is quite early stage but it looks stable enough for us to use. This is a probably the best starting point. We also have the <code>monad-bayes</code> the library so it shouldn&rsquo;t be a huge step re-implementing, and if it works, it would obviously be the best suggestion. Why rewrite everything in a complex way when you can just move to the same system but better?</p>
</li>
<li>
<p>One of the next best (computationally-related) goals would be to work out how to get Alexis King&rsquo;s patch and library working. This looks like the patch branch: <a href="https://github.com/lexi-lambda/ghc-proposals/tree/delimited-continuation-primops">https://github.com/lexi-lambda/ghc-proposals/tree/delimited-continuation-primops</a></p>
</li>
<li>
<p>How do we turn this into research, rather than simply an application of a different effect system to an existing library?</p>
</li>
<li>
<p>The research aspect would be comparing the different methods in my opinion. If we&rsquo;re looking for new <em>things</em>, then maybe the stuff NW is working on? It is possible that <em>just</em> staging it or <em>just</em> using codensity/fusion stuff would count as novel research, given that JW has a paper on staging parsley. Additionally, we believe that case studies/methodology papers like &ldquo;how to optimise something built on an effect system&rdquo; are important research, however sometimes academia can be a bit snooty.</p>
</li>
<li>
<p>If we think a case study methodology is too risky (out of a fear of some kind of lack of appreciation) maybe just staging or doing fusion would be best as that would be novel. Staging is just more involved and would require more novel insight / the path is less charted, whereas <code>eff</code> would likely be easier to reimplement <code>monad-bayes</code> with essentially. If we feel more inclined to take a case study approach initially, going to <code>eff</code> would be the best first move. Either option is plausible, but we&rsquo;ll end up doing <code>eff</code> either way as it&rsquo;s the best bet to actually make it faster.
Additionally, we&rsquo;ll be able to reach a milestone faster and feel a bit better about taking other approaches.</p>
</li>
<li>
<p>Optimistically, we could get the <code>eff</code> content done by the end of the year or early January.</p>
</li>
</ul>
<p><strong>Meeting (MN + AZ)</strong>     <em>12/11/2020</em></p>
<p>Analysing profile report on PMMH inference for a HMM:</p>
<p><img src="https://i.ibb.co/6mv24Cp/pmmh-prof.png" alt=""></p>
<p>The key points of interest are:</p>
<ul>
<li>
<p>The <code>(&gt;&gt;=)</code> operation which occurs in <code>Population.hs</code>, accounting for 35% of the total runtime. The source line responsible for this is found in the typeclass derivations of the <code>Population</code> newtype, namely the deriving of the <code>Monad</code> class.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#75715e">-- | A collection of weighted samples, or particles.</span>
<span style="color:#66d9ef">newtype</span> <span style="color:#66d9ef">Population</span> m a <span style="color:#f92672">=</span> <span style="color:#66d9ef">Population</span> (<span style="color:#66d9ef">Weighted</span> (<span style="color:#66d9ef">ListT</span> m) a)
  <span style="color:#66d9ef">deriving</span> (<span style="color:#66d9ef">Functor</span>, <span style="color:#66d9ef">Applicative</span>, <span style="color:#66d9ef">Monad</span>, <span style="color:#66d9ef">MonadIO</span>, <span style="color:#66d9ef">MonadSample</span>, <span style="color:#66d9ef">MonadCond</span>, <span style="color:#66d9ef">MonadInfer</span>)
</code></pre></div></li>
<li>
<p>The <code>liftA2</code> operation and the <code>pure</code> operation which both occur in <code>Weighted.hs</code>, accounting for 11.9% and 7.9% of the total runtime respectively. The source line responsible for this is found in the typeclass derivations of the <code>Weighted</code> newtype, namely the deriving of the <code>Applicative</code> class.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#75715e">-- | Execute the program using the prior distribution, while accumulating likelihood.</span>
<span style="color:#66d9ef">newtype</span> <span style="color:#66d9ef">Weighted</span> m a <span style="color:#f92672">=</span> <span style="color:#66d9ef">Weighted</span> (<span style="color:#66d9ef">StateT</span> (<span style="color:#66d9ef">Log</span> <span style="color:#66d9ef">Double</span>) m a)
  <span style="color:#75715e">-- StateT is more efficient than WriterT</span>
  <span style="color:#66d9ef">deriving</span> (<span style="color:#66d9ef">Functor</span>, <span style="color:#66d9ef">Applicative</span>, <span style="color:#66d9ef">Monad</span>, <span style="color:#66d9ef">MonadIO</span>, <span style="color:#66d9ef">MonadTrans</span>, <span style="color:#66d9ef">MonadSample</span>)
</code></pre></div></li>
</ul>
<p>These overheads are associated with the inference representations/transformer stack which <code>monad-bayes</code> uses, as opposed to time spent on numerical computation such as with the <code>bernoulli</code> function.</p>
<p>This prompts the questions:</p>
<ul>
<li>What definitions of <code>(&gt;&gt;=)</code>, <code>liftA2</code>, and <code>pure</code> are generated as a result of using <code>deriving</code>, and why are these inefficient for our case?</li>
</ul>
<p><strong>Meeting (MN + AZ + JW)</strong>     <em>13/11/2020</em></p>
<p>Following the previous meeting, this was an extremely helpful discussion (with JW) about how to proceed given the profiler report. Content from this meeting is fully elaborated on <a href="./../../benchmarking/haskell-core">here</a>.
Briefly summarised, we were introduced to:</p>
<ul>
<li>The ghc-option/dependency <code>dump-core</code> as a means of finding out what core Haskell code is generated from surface-level Haskell code</li>
<li>How to understand various core-level syntax</li>
<li>The general workflow needed when investigating/identifying inefficiencies in programs</li>
<li>Common problematic fragments of code to look out for in the core program.</li>
</ul>
<p>Thoughts:</p>
<ul>
<li>There is definitely a place for a good tutorial paper on how to do all of this (understanding Haskell core, the relationship between surface-level code and core, and identifying possible optimisations). If we pay strong attention to what we do in the next few weeks and write up our process, this would be a good contribution towards the general question of how to optimise a Haskell program. What we&rsquo;re about to do is what a lot of people do without any resources. A quick outline of such a paper would be to: 1) emphasize the process of profiling your code dumping the core of the highly used functions, and 2) distill what it is one should looking out for in the core. This could be a good Haskell symposium paper.</li>
</ul>
<p>From this, our next targets are:</p>
<ul>
<li>Compile <code>monad-bayes</code> with the <code>dump-core</code> plugin on, and invest time in figuring out where performance issues lie in the core code.</li>
<li>Writing the hand-rolled versions of instances for all the inference transformers of <code>monad-bayes</code> (there&rsquo;s an incomplete page <a href="./../../background/performance-w-monads">here</a> on unrolling monad transformers), and compare the core for both the hand-rolled version and the <code>monad-bayes</code> library itself, and identify what is slow.</li>
<li>Look for some resources (e.g. tutorials or talks) on understanding core.</li>
<li>To record/write up our workflow and stream of consciousness as we progress on understanding how to optimise <code>monad-bayes</code> by using core.</li>
<li>Have a work session during weekend on 21/11/2020</li>
</ul>
<p><strong>Debugging - Getting dump-core to work (AZ + MN)</strong>     <em>16/11/2020</em></p>
<ul>
<li>
<p>Adding the ghc-option and dependencies for <code>dump-core</code> in <code>package.yaml</code> gives us the following error:</p>
<p><img src="https://i.ibb.co/dks5SZ8/dump-core-1.png" alt=""></p>
</li>
<li>
<p>From this, adding the extra dependency <code>dump-core-0.1.3.2</code> in <code>stack.yaml</code> gives us the below error. This is a resolver error i.e. stack can not resolve the constraints of the packages. Stack works by collecting bunches of packages that work together and calls them an lts (long-time-support). The constraint is generated by <code>dump-core</code>, which says that the version of <code>base</code> that our stack project uses does not match the version of <code>base</code> that <code>dump-core</code> uses, i.e. we need a version of <code>base</code> from <code>&gt;=4.9 &amp; &lt; 4.13</code>, and the most recent version satisfying this constraint is <code>4.12.0</code>.</p>
<p><img src="https://i.ibb.co/S70dkJs/dump-core-3.png" alt=""></p>
</li>
<li>
<p>Looking at the various <code>lts</code> versions, the resolver version <code>lts-14.1</code> supports <code>base</code> version <code>4.12.0</code>, which uses <code>GHC</code> version <code>8.6.5</code>.</p>
<p><img src="https://i.ibb.co/5Y2L4sV/dump-core-5.png" alt=""></p>
</li>
<li>
<p>Setting <code>resolver</code> to <code>lts-14.1</code> then gives the following extra dependency error:</p>
<p><img src="https://i.ibb.co/tpdc1x6/dump-core-6.png" alt=""></p>
</li>
<li>
<p>Introducing these extra dependencies then finally solves the problem:</p>
<p><img src="https://i.ibb.co/54696LK/dump-core-4.png" alt=""></p>
</li>
<li>
<p>Running <code>stack build</code> now generates a folder called <code>dump-core</code>, containing <code>html</code> files for visualisations of the core Haskell code generated from our program.</p>
<p><img src="https://i.ibb.co/9sqQwzG/dump-core-7.png" alt=""></p>
</li>
</ul>
<p><strong>Debugging - Getting dump-core to generate the desired files (MN)</strong>     <em>18/11/2020</em></p>
<ul>
<li>
<p>Given the below configuration of <code>package.yaml</code>, cabal does not generate any executables for the <code>library</code> fields, so running <code>stack build</code> with <code>dump-core</code> will unhelpfully generate a <code>Paths_&lt;package_name&gt;.html</code> file, part of which represents our code found in the <code>src</code> directory.</p>
<p><img src="https://i.ibb.co/DGFsDPT/dump-core-1-0.png" alt=""></p>
</li>
<li>
<p>In order to generate core for desired files in directory <code>src</code>, we need to either:</p>
<ol>
<li>Move <code>Main.hs</code> to <code>src</code> and change the <code>source-dirs</code> field under <code>executables</code> from <code>app</code> to <code>src</code></li>
<li>Add <code>src</code> to the <code>source-dirs</code> field under <code>executables</code>, and add the <code>dependencies</code> under <code>library</code> to the <code>dependencies</code> under <code>executables</code>.
The second option is shown below:</li>
</ol>
<p><img src="https://i.ibb.co/D16HmRt/dump-core-1-1.png" alt=""></p>
</li>
</ul>
<p><strong>Meeting (MN + AZ)</strong>     <em>19/11/2020</em></p>
<p>To do in preparation for work session on Sunday (22/11/2020):</p>
<ul>
<li>Clone <code>monad-bayes</code> and link it as a local library by placing it in the same stack project/folder as <code>probalistic-programming</code>. Then dump the core code for it.</li>
<li>Read and write up <a href="https://wiki.haskell.org/Performance/GHC#Looking_at_the_Core">tutorials</a> on core + get a gist of existing resources around optimising Haskell and what remains unexplored/unwritten about.</li>
<li>Familiarise ourselves with hand-rolling monad transformers.</li>
</ul>
<p><strong>Meeting (MN + MW + RP)</strong>     <em>19/11/2020</em></p>
<ul>
<li>It&rsquo;s useful to know if performance improves linearly/asymptotically or remains linear/asymptotic, following the first attempt at optimising <code>monad-bayes</code> e.g. by hand-rolling the inference transformers.</li>
<li>In response to the question on using <code>Eff</code>, &ldquo;how do we turn this into research, rather than simply an application of a different effect system to an existing library?&rdquo;, we can ask ourselves whether this application is straightforward. If it isn&rsquo;t straightforward, then there&rsquo;s probably a research element in it. It is definitely right to try to use what existing libraries/tools are already there. The suspicion is that, along the way, we will find something within these existing approaches that is worth researching, as there will be some problems to be addressed and changes to be made. Until we have exhausted existing options, it would be wrong to start our own. This would be a requirement from reviewers that we are not reinventing the wheel.</li>
<li><code>Eff</code> is not a mature library at all - if we were to make progress understanding and using it to reimplement the <code>monad-bayes</code> system in that setting, that would already be building towards some sort of contribution which a lot of interesting stuff is likely to come out of.
Eventually, it could maybe feed into the evolution of the <code>Eff</code> library, or similarly with <code>monad-bayes</code>. There are two or three different directions we could imagine making progress in: one is a better version of <code>monad-bayes</code> or probabilistic programming in Haskell, another is a better version of <code>Eff</code>.</li>
<li>The current direction is already definitely research/publishable somewhere, the only question is if it is ICFP etc. We&rsquo;re in a good position in the sense that we have quite an ambitious goal in mind and we have a plan with multiple paths of achieving that, but we haven&rsquo;t arrived yet because we don&rsquo;t know what we&rsquo;ll end up with. It&rsquo;s extremely likely that opportunities (for getting side-tracked onto more concrete research) will appear during this process.</li>
<li>We have atleast two concrete targets at the moment: 1) Using <code>Eff</code> to reimplement <code>monad-bayes</code> (sounds like a good thing to pursue) 2) Hand-rolling <code>monad-bayes</code> and seeing if there is some kind of asymptotic change in performance, and if there is, then we&rsquo;ve atleast identified the problem there.</li>
<li>Research almost always starts with a concrete example - once we understand it, then we can see how much we can generalise it.</li>
<li>It&rsquo;s a good sign that we are taking ideas from multiple sources, and indicates that the work is not straightforward. (Taking an idea from one paper and applying it, is quite worrying, whereas being able to show that we have taken ideas from multiple papers is promising.)</li>
<li>Good idea to collect a literature review around <code>probabilistic-effects</code> in order to have a more concrete mind-map of research directions, and organize them around how they might contribute to our research going forward.</li>
</ul>
<p><strong>Activity (MN)</strong>     <em>20/11/2020</em></p>
<ul>
<li>Added <a href="./literature-review">literature review</a>.</li>
<li>Cloned <code>monad-bayes</code> as a local package to <a href="https://github.com/probabilistic-effects/probabilistic-programming"><code>probabilistic-programming</code></a> repo and re-organized project.</li>
<li>Dumped the core of <code>monad-bayes</code>.</li>
</ul>
<p><strong>Meeting (MN + AZ)</strong>     <em>22/11/2020</em></p>
<ul>
<li>Looked at core of files <code>Population.hs</code> and <code>Weighted.hs</code> from <code>monad-bayes</code>.</li>
<li>The two components of interest from the profiling report were:
<ul>
<li>
<p><code>(&gt;&gt;=)</code> from <code>Population.hs</code>, which is essentially how <code>(&gt;&gt;=)</code> works for <code>StateT (Log Double) (ListT m) a)</code> if we ignore the <code>newtype</code> wrappers.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#66d9ef">newtype</span> <span style="color:#66d9ef">Population</span> m a <span style="color:#f92672">=</span> <span style="color:#66d9ef">Population</span> (<span style="color:#66d9ef">Weighted</span> (<span style="color:#66d9ef">ListT</span> m) a)
  <span style="color:#66d9ef">deriving</span> (<span style="color:#66d9ef">Functor</span>, <span style="color:#66d9ef">Applicative</span>, <span style="color:#66d9ef">Monad</span>, <span style="color:#66d9ef">MonadIO</span>, <span style="color:#66d9ef">MonadSample</span>, <span style="color:#66d9ef">MonadCond</span>, <span style="color:#66d9ef">MonadInfer</span>)
</code></pre></div><p>The version of <code>StateT</code> that <code>monad-bayes</code> uses is from the <code>mtl-2.2.2</code> library.</p>
<p><img src="https://i.ibb.co/1LJQjTw/dump-core-2-6.png" alt=""></p>
</li>
<li>
<p><code>liftA2</code> and <code>pure</code> from <code>Weighted.hs</code>, which is essentially how <code>liftA2</code> and <code>pure</code> work for <code>StateT (Log Double) m a</code> if we ignore the <code>newtype</code> wrapper.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-haskell" data-lang="haskell"><span style="color:#66d9ef">newtype</span> <span style="color:#66d9ef">Weighted</span> m a <span style="color:#f92672">=</span> <span style="color:#66d9ef">Weighted</span> (<span style="color:#66d9ef">StateT</span> (<span style="color:#66d9ef">Log</span> <span style="color:#66d9ef">Double</span>) m a)
  <span style="color:#66d9ef">deriving</span> (<span style="color:#66d9ef">Functor</span>, <span style="color:#66d9ef">Applicative</span>, <span style="color:#66d9ef">Monad</span>, <span style="color:#66d9ef">MonadIO</span>, <span style="color:#66d9ef">MonadTrans</span>, <span style="color:#66d9ef">MonadSample</span>)
</code></pre></div><p>The version of <code>ListT</code> that <code>monad-bayes</code> uses if from the <code>transformers-0.5.2.0</code> library (this is deprecated in all later versions).</p>
<p><img src="https://i.ibb.co/4t4nkY8/dump-core-2-4.png" alt="">
<img src="https://i.ibb.co/4Y0Hdyp/dump-core-2-5.png" alt=""></p>
<p>We were unable to expand out the generated core of these, as <code>StateT</code> and <code>ListT</code> belong to libraries external to the stack project. Hence, the next steps were to clone the necessary libraries locally and dump their core.</p>
</li>
</ul>
</li>
<li>Cloned <code>mtl-2.2.2</code> locally into <a href="https://github.com/probabilistic-effects/probabilistic-programming"><code>probabilistic-programming</code></a> repo. (The local copy of <code>monad-bayes</code> does not yet use the local version of <code>mtl-2.2.2</code>.)
<img src="https://i.ibb.co/bz1YT6Y/dump-core-2-0.png" alt=""></li>
<li>Dumped the core of <code>mtl-2.2.2</code>.</li>
<li>Tried to clone <code>transformers-0.5.2.0</code> locally into <a href="https://github.com/probabilistic-effects/probabilistic-programming"><code>probabilistic-programming</code></a> repo, but ran into &ldquo;duplicate instance declarations&rdquo; error due to the definitions in the local <code>transformers-0.5.2.0</code> package clashing with <code>GHC.Base</code>. Currently unsure how to solve this.
<img src="https://i.ibb.co/PQbmvjd/dump-core-2-2.png" alt="">
<img src="https://i.ibb.co/xz0nvJm/dump-core-2-1.png" alt=""></li>
<li>Discussed/learned about process of handrolling monad transformers in <code>mtl</code>.</li>
</ul>
<p><strong>Activity (MN)</strong>     <em>23/11/2020</em></p>
<ul>
<li>
<p>Explained issue to JW about being unable to expand definitions for <code>&gt;&gt;=</code> and <code>liftA2</code> in core for <code>monad-bayes</code>, and having trouble cloning and dumping the core of the <code>mtl</code> and <code>transformers</code> libraries locally.</p>
<p>JW : Being unable to expand out definitions for <code>&gt;&gt;=</code> and <code>liftA2</code> is problematic to begin with - if the dumped core has referenced these functions, then the inliner isn&rsquo;t doing its job. In <a href="https://github.com/J-mie6/ParsleyHaskell"><code>parsley</code></a> which is a cabal project, he has compiled with <code>-O2</code> by placing <code>optimization:2</code> in the <a href="https://github.com/J-mie6/ParsleyHaskell/blob/master/cabal.project"><code>cabal.project</code></a> file, which allows this inlining to occur.</p>
</li>
<li>
<p>As we&rsquo;re using stack, I&rsquo;m currently unable to find how the optimization flag translates into a <code>package.yaml</code> or <code>stack.yaml</code> file (it&rsquo;s definitely not <code>ghc-options: O2</code>). Next step is to figure out cabal, create a cabal project for <a href="https://github.com/probabilistic-effects/probabilistic-programming"><code>probabilistic-programming</code></a>, add the <code>optimization:2</code> option, and inspect if anything has changed in the dumped core.</p>
</li>
</ul>
<p><strong>Meeting (MN + SF + MW + WZ)</strong>     <em>24/11/2020</em></p>
<ul>
<li>A big flaw of <code>monad-bayes</code> is that they are calling references, so inlining will speed this up; for some this is folklore, for others they just aren&rsquo;t aware. This is an topic we should probably try and clarify (pass knowledge on) to people.</li>
<li>A good idea is to explore how relevant this occurence actually is and see if others have this problem. Software developers can write refutal papers which is uncommon in functional programming. To write these papers the paper to be refuted must either be an important example, or address many less important examples. Hence for such a proposed paper to be written, we should find one important example of this problem, or many small ones.</li>
</ul>
<p><strong>Activity (MN)</strong>     <em>24/11/2020</em></p>
<ul>
<li>
<p>Got out of cabal hell</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">sudo apt-get remove --auto-remove cabal-install
sudo apt-get purge cabal-install
</code></pre></div></li>
<li>
<p>Installed <code>ghcup</code> which allows me to set versions of <code>ghc</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">curl https://gitlab.haskell.org/haskell/ghcup/raw/master/bootstrap-haskell -sSf | sh
source /home/minh/.ghcup/env
ghcup upgrade
. <span style="color:#e6db74">&#34;</span>$HOME<span style="color:#e6db74">/.ghcup/env&#34;</span>
echo <span style="color:#e6db74">&#39;. $HOME/.ghcup/env&#39;</span> &gt;&gt; <span style="color:#e6db74">&#34;</span>$HOME<span style="color:#e6db74">/.bashrc&#34;</span>
</code></pre></div></li>
<li>
<p>Set up new cabal project for <code>probabilistic-programming</code>, using <code>ghc-8.6.5</code>, containing <code>monad-bayes</code> locally and the original code for HMM simulation and PMMH inference which uses <code>monad-bayes</code> as a non-local build dependency.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">mkdir probabilistic-programming
cd probabilistic-programming
cabal init -n --is-executable
ghcup install 8.6.5
ghcup set 8.6.5
</code></pre></div></li>
<li>
<p>Added <code>cabal.project</code> file with <code>optimization:2</code> flag to project, and then analysed the dumped core of <code>Population.hs</code> and <code>Weighted.hs</code> of <code>monad-bayes</code>.</p>
<p><img src="https://i.ibb.co/RpdvP7G/image-14.png" alt=""></p>
<p>It turns out that we should expect to see these definitions, however if we use <code>optimization:2</code>, then we should also expect them to not actually be used. This is because GHC generates a lot of garbage that it doesn&rsquo;t seem to want to remove, but when we go to places where they would have been used, we should be able to find that they aren&rsquo;t actually there.</p>
</li>
<li>
<p>Here is <code>scoreModel</code> from <code>PmmhHmm.hs</code> of <code>probabilistic-programming</code>.</p>
<p><img src="https://i.ibb.co/nPg76CB/image-12.png" alt="">
<img src="https://i.ibb.co/0VRhHLW/image-11.png" alt=""></p>
<p>We can see that there aren&rsquo;t any of the abstractions in there; this core looks pretty good, however <code>logProbability</code> is a numerical computation which could be inlined.</p>
</li>
<li>
<p>The hope is that we won&rsquo;t find any <code>&gt;&gt;=</code>s if the optimiser has successfully removed them from the function. If we look at the <code>pmmh</code> function from <code>PMMH.hs</code> of <code>monad-bayes</code>:</p>
<p><img src="https://i.ibb.co/vwTBtrR/image-9.png" alt="">
<img src="https://i.ibb.co/hXWdFpv/image-8.png" alt=""></p>
<p>This function itself won&rsquo;t be able to optimise because it needs a concrete instance of <code>MonadInfer</code>, but this isn&rsquo;t necessarily a problem. What we need to look at is when we <em>use</em> this function with something concrete. So let&rsquo;s look at <code>inferModel</code> from <code>PmmhHmm.hs</code> of <code>probabilistic-programming</code> which uses <code>pmmh</code>; the <code>MonadInfer m</code> concretises to <code>IO</code> because we called <code>sampleIO</code> of <code>monad-bayes</code> on it.</p>
<p><img src="https://i.ibb.co/Hn11cqs/image-6.png" alt="">
<img src="https://i.ibb.co/L8sSSFZ/image-5.png" alt=""></p>
<p>The hope is that the call to <code>pmmh</code> (represented by the green-highlighted <code>lvl</code>) would have been inlined - however this is not the case, as it simply references <code>pmmh</code> from the <code>monad-bayes</code> library, which has <em>not</em> been marked as <code>INLINE</code> or <code>INLINABLE</code>. This means GHC isn&rsquo;t specialising it, so the program still performs dictionary lookups when that code is compiled.</p>
</li>
<li>
<p>The <code>monad-bayes</code> library from <code>hackage</code> was removed as a build dependency, and the local clone of <code>monad-bayes</code> is now used as a dependency instead.</p>
<p><img src="https://i.ibb.co/QXTPhZ4/dump-core-3-0.png" alt=""></p>
</li>
<li>
<p>The <code>INLINE</code> pragma was added to <code>pmmh</code> of <code>monad-bayes</code>.</p>
<p><img src="https://i.ibb.co/MZ15RN0/dump-core-3-1.png" alt=""></p>
<p>Revisiting the <code>inferModel</code> function, we can now see that the call to <code>pmmh</code> (previously represented by <code>lvl</code>) has been inlined with what is now called <code>$w$spmmh</code>.</p>
<ul>
<li><code>$w</code> is usually prepended to functions that the compiler has unwrapped some of the arguments for (which eliminates a pattern match).</li>
<li><code>$s</code> is usually prepended to functions that the compiler has specialised.</li>
</ul>
</li>
<li>
<p>Let&rsquo;s now visit the new version of <code>pmmh</code>, called <code>$w$spmmh</code>.</p>
<p><img src="https://i.ibb.co/SQb1B5P/image-3.png" alt=""></p>
<p>This immediately looks a lot better than before, as it has been specialised and has had its arguments unwrapped. There still exists some possible optimisations. When seeing occurrences of calls such as <code>$s$fMonadStateT_$c&gt;&gt;=</code>, we can see it&rsquo;s being passed to <code>mhTrans</code> - this is concerning and suggests that <code>mhTrans</code> along with other functions in similar situations such as <code>pushEvidence</code> and <code>hoist</code> can be inlined.</p>
<p>Placing an <code>INLINE</code> pragma on these functions results in the following core, with the previous calls being inlined:</p>
<p><img src="https://i.ibb.co/HC0Yqj8/image-1.png" alt=""></p>
<p>Additionally, the <code>$w$c&gt;&gt;=</code> (from <code>Bayes.Traced.Static</code>) at the top is suspicious - it looks like one of the arguments is a monadic value, and so it&rsquo;s forced to use a <code>&gt;&gt;=</code> because it doesn&rsquo;t know what the monadic value is.</p>
</li>
</ul>
<p><strong>Activity (MN)</strong>     <em>25/11/2020</em></p>
<ul>
<li>
<p>Learning and writing up of a <a href="./../haskell-core">small case study</a> on optimising <code>Parsley</code> using Haskell core.</p>
</li>
<li>
<p>Organized <code>probabilistic-programming</code> repo, and added benchmarking program and folder.</p>
</li>
</ul>
<div class="edit-meta">
Last updated on 13 Nov 2020


<br>
Published on 13 Nov 2020
<br></div><nav class="pagination"><a class="nav nav-prev" href="https://probabilistic-effects.github.io/research/" title="Research"><i class="fas fa-arrow-left" aria-hidden="true"></i> Prev - Research</a>
<a class="nav nav-next" href="https://probabilistic-effects.github.io/research/approaches-for-monad-bayes/" title="Potential Approaches to Improving Monad Bayes">Next - Potential Approaches to Improving Monad Bayes <i class="fas fa-arrow-right" aria-hidden="true"></i></a>
</nav><footer><p class="powered">Powered by <a href="https://gohugo.io">Hugo</a>. Theme by <a href="https://themes.gohugo.io/hugo-theme-techdoc/">TechDoc</a>. Designed by <a href="https://github.com/thingsym/hugo-theme-techdoc">Thingsym</a>.</p>
</footer>
</main>
<div class="sidebar">

<nav class="open-menu">
<ul>
<li class=""><a href="https://probabilistic-effects.github.io/">Home</a></li>

<li class="parent"><a href="https://probabilistic-effects.github.io/research/">Research</a>
  
<ul class="sub-menu">
<li class="active"><a href="https://probabilistic-effects.github.io/research/research-journal/">Research Journal</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/approaches-for-monad-bayes/">Potential Approaches to Improving Monad Bayes</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/effects-for-less/">Effects for Less</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/literature-review/">Literature Review</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/research/haskell-core/">Haskell Core</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/">Monad Bayes</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/inference-transformers/">Inference Transformers</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/pmmh-hmm/">Implementing HMM Simulation and Inference (using PMMH)</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/monad-bayes/conditioning-scoring/">How Conditioning and Scoring Works</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/tooling/">Tooling</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/tooling/cabal/">Cabal</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/">Benchmarking</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/benchmarking-profiling/">How to Benchmark and Profile</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/benchmarking/monad-bayes-components/">Relevant Components of Monad Bayes for Profiling</a></li>
</ul>
  
</li>

<li class=""><a href="https://probabilistic-effects.github.io/background/">Background</a>
  
<ul class="sub-menu">
<li class=""><a href="https://probabilistic-effects.github.io/background/staging/">Staging</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/smc-pmmh/">SMC and PMMH</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/performance-w-monads/">Performance With Monads</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/mtl/">MTL</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/mcmc-mh/">MCMC and MH</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/markov-chain/">Markov Chains</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/hidden-markov-model/">Hidden Markov Model</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/delimited-continuations/">Delimited Continuations</a></li>
<li class=""><a href="https://probabilistic-effects.github.io/background/continuations/">Continuations</a></li>
</ul>
  
</li>
</ul>
</nav>



<div class="sidebar-footer"></div>
</div>

</div><a href="#" id="backtothetop-fixed" class="backtothetop"
 data-backtothetop-duration="600"
 data-backtothetop-easing="easeOutQuart"
 data-backtothetop-fixed-fadeIn="1000"
 data-backtothetop-fixed-fadeOut="1000"
 data-backtothetop-fixed-bottom="10"
 data-backtothetop-fixed-right="20">
<span class="fa-layers fa-fw">
<i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i>
</span></a>
</div>
</body>
</html>
