<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Benchmarking on Probabilistic Effects.  λθ</title>
    <link>https://probabilistic-effects.github.io/benchmarking/</link>
    <description>Recent content in Benchmarking on Probabilistic Effects.  λθ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Nov 2020 13:49:05 +0000</lastBuildDate><atom:link href="https://probabilistic-effects.github.io/benchmarking/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How to Benchmark and Profile</title>
      <link>https://probabilistic-effects.github.io/benchmarking/benchmarking-profiling/</link>
      <pubDate>Fri, 13 Nov 2020 14:02:28 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/benchmarking/benchmarking-profiling/</guid>
      <description>Benchmarking With Criterion &amp;amp; Stack   The benchmark program we intend to profile needs to have a function which takes one argument (influencing the computational effort of executing the program) - this is the function we directly call for profiling.
This should be under the test directory, e.g. test/BenchmarkProgram.hs which contains a function:
testPmmh :: Int -&amp;gt; IO () testPmmh nsteps = do observedStates &amp;lt;- generateData initLatentState initParams nsteps print observedStates   The program that calls the profiling functions should ideally be test/Spec.</description>
    </item>
    
    <item>
      <title>Relevant Components of Monad Bayes for Profiling</title>
      <link>https://probabilistic-effects.github.io/benchmarking/monad-bayes-components/</link>
      <pubDate>Fri, 13 Nov 2020 14:01:54 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/benchmarking/monad-bayes-components/</guid>
      <description>What constitutes a good benchmark - Concrete components/transformers of interest:
These are plausible components for benchmarking the performance of individual concrete transformers.
  SamplerIO
-- | An &amp;#39;IO&amp;#39; based random sampler using the MWC-Random package. newtype SamplerIO a = SamplerIO (ReaderT GenIO IO a) deriving (Functor, Applicative, Monad, MonadIO)   SamplerST
-- | An &amp;#39;ST&amp;#39; based random sampler using the MWC-Random package. newtype SamplerST a = SamplerST (forall s.</description>
    </item>
    
    <item>
      <title>Haskell Core</title>
      <link>https://probabilistic-effects.github.io/benchmarking/haskell-core/</link>
      <pubDate>Fri, 13 Nov 2020 13:49:05 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/benchmarking/haskell-core/</guid>
      <description>Understanding Haskell Core The best way to understand why a profiling report outputs certain performance metrics (for Haskell) is to dive into the actual core itself, which is what the surface-level Haskell code compiles down into. To inspect the core in a coherent manner, we can add the following to either our package.yaml file (when using stack):
ghc-options: - dump-core dependencies: - -fplugin=DumpCore or our .cabal file (when using cabal):</description>
    </item>
    
  </channel>
</rss>
