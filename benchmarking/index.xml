<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Benchmarking on Probabilistic Effects.  λθ</title>
    <link>https://probabilistic-effects.github.io/benchmarking/</link>
    <description>Recent content in Benchmarking on Probabilistic Effects.  λθ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Nov 2020 13:49:05 +0000</lastBuildDate><atom:link href="https://probabilistic-effects.github.io/benchmarking/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Benchmark Log</title>
      <link>https://probabilistic-effects.github.io/benchmarking/benchmark-log/</link>
      <pubDate>Fri, 13 Nov 2020 14:02:28 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/benchmarking/benchmark-log/</guid>
      <description>PMMH Inference on HMM This details the benchmarks for a program using monad-bayes to run PMMH inference on a HMM, whilst tactically adding various {-# INLINE #-} pragmas to functions of the monad-bayes library in response to analysing the Haskell core generated. Each benchmark is the average over 4 iterations.
Source Program
main = defaultMain [ bgroup &amp;#34;runPmmh&amp;#34; [ bench &amp;#34;(100, 100, 100)&amp;#34; $ whnfIO $ runPmmh (100, 100, 100) ] ] runPmmh :: (Int, Int, Int) -&amp;gt; IO () runPmmh (n_mhsteps, n_timesteps, n_particles) = do particleWeightings &amp;lt;- inferModel n_mhsteps n_timesteps n_particles print particleWeightings  Original Code   Inline pragma added to pmmh function   Inline pragma added to pmmh &amp;amp; pushEvidence functions   Inline pragma added to pmmh, pushEvidence, &amp;amp; hoist functions   Inline pragma added to pmmh, pushEvidence, hoist, &amp;amp; mhTrans functions  </description>
    </item>
    
    <item>
      <title>How to Benchmark and Profile</title>
      <link>https://probabilistic-effects.github.io/benchmarking/benchmarking-profiling/</link>
      <pubDate>Fri, 13 Nov 2020 14:02:28 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/benchmarking/benchmarking-profiling/</guid>
      <description>Benchmarking With Criterion &amp;amp; Stack   The benchmark program we intend to profile needs to have a function which takes one argument (influencing the computational effort of executing the program) - this is the function we directly call for profiling.
This should be under the test directory, e.g. test/BenchmarkProgram.hs which contains a function:
testPmmh :: Int -&amp;gt; IO () testPmmh nsteps = do observedStates &amp;lt;- generateData initLatentState initParams nsteps print observedStates   The program that calls the profiling functions should ideally be test/Spec.</description>
    </item>
    
    <item>
      <title>Relevant Components of Monad Bayes for Profiling</title>
      <link>https://probabilistic-effects.github.io/benchmarking/monad-bayes-components/</link>
      <pubDate>Fri, 13 Nov 2020 14:01:54 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/benchmarking/monad-bayes-components/</guid>
      <description>What constitutes a good benchmark - Concrete components/transformers of interest:
These are plausible components for benchmarking the performance of individual concrete transformers.
  SamplerIO
-- | An &amp;#39;IO&amp;#39; based random sampler using the MWC-Random package. newtype SamplerIO a = SamplerIO (ReaderT GenIO IO a) deriving (Functor, Applicative, Monad, MonadIO)   SamplerST
-- | An &amp;#39;ST&amp;#39; based random sampler using the MWC-Random package. newtype SamplerST a = SamplerST (forall s.</description>
    </item>
    
  </channel>
</rss>
