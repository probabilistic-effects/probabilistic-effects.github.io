<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Index on Probabilistic Effects.  λθ</title>
    <link>https://probabilistic-effects.github.io/</link>
    <description>Recent content in Index on Probabilistic Effects.  λθ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Nov 2020 14:05:57 +0000</lastBuildDate><atom:link href="https://probabilistic-effects.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Research Journal</title>
      <link>https://probabilistic-effects.github.io/research/research-journal/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:57 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/research-journal/</guid>
      <description>Activity (MN) 17/12/2020
 Wrote up JW&amp;rsquo;s continuation passing style example More analysis and inlining of monad-bayes  Activity (MN) 16/12/2020
 Getting deep into investigating and optimising core of monad-bayes (with help of JW). Writing up optimising core.  Meeting (MN + RP + MW) 15/12/2020
 Todo: look at handwriting some monad-bayes, and get more involved with Haskell core  Activity (MN) 11/12/2020 - 14/12/2020
 Reading, implementing, and writing up of Fusion for Free (fusion-for-free).</description>
    </item>
    
    <item>
      <title>Cabal Projects</title>
      <link>https://probabilistic-effects.github.io/tooling/cabal/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/tooling/cabal/</guid>
      <description>The executable field specifies the part of the package which can be executed with cabal run &amp;lt;executable&amp;gt;.
 main-is - The executable file containing a Main module and the function main. build-depends - Other library packages from which modules are imported. This can contain modules from the current package itself if they are found in the exposed-modules field of the library, by specifying the name of our package. hs-source-dirs - The local directories from which the executable can be found (leave empty if it isn&amp;rsquo;t inside a directory) and any other local modules it imports (if they aren&amp;rsquo;t found in the build-depends field).</description>
    </item>
    
    <item>
      <title>Freer Monads, More Extensible Effects</title>
      <link>https://probabilistic-effects.github.io/papers/freer-monads/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/papers/freer-monads/</guid>
      <description>1. Derivation of Free-er Monad 1.1 Reader Effect Reader computations depend on a value supplied by the environment/context. A side-effect can be understood as an interaction of an expression with its context. The possible requests of a Reader can be specified as a data type.
data It i a = Pure a | Get (i -&amp;gt; It i a) The expression Pure e marks the computation e that makes no requests, silently working towards a value of the type a.</description>
    </item>
    
    <item>
      <title>Fusion for Free</title>
      <link>https://probabilistic-effects.github.io/papers/fusion-for-free/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/papers/fusion-for-free/</guid>
      <description>Free monads are at the heart of algebraic effect handlers, a functional approach for modelling side effects which allows the separation of the syntax and semantics of effectful operations, whilst enabling us to provide multiple different semantics for the same syntax.
The syntax of primitive side-effect operations is captured in a signature functor. The free monad over this functor assembles the syntax for the individual operations into an abstract syntax tree for an effectful program.</description>
    </item>
    
    <item>
      <title>Inlining Monad Bayes</title>
      <link>https://probabilistic-effects.github.io/activity/inlining-monad-bayes/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/activity/inlining-monad-bayes/</guid>
      <description>Original profiling report for PMMH inference on a HMM:
  Analysing the dumped core of Population.hs and Weighted.hs of monad-bayes:
It turns out that we should expect to see these definitions, however if we use optimization:2, then we should also expect them to not actually be used. This is because GHC generates a lot of garbage that it doesn&amp;rsquo;t seem to want to remove, but when we go to places where they would have been used, we should be able to find that they aren&amp;rsquo;t actually there.</description>
    </item>
    
    <item>
      <title>Potential Approaches to Improving Monad Bayes</title>
      <link>https://probabilistic-effects.github.io/research/approaches-for-monad-bayes/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/approaches-for-monad-bayes/</guid>
      <description>Possible approaches to optimising effect systems:
 Different effects system - taking a look at the core effect library as a whole Different concrete transformers - the effects aren’t disappearing when using monad transformers  Effects for Less (Eff library) - Alexis King (Delimited continuations approach)   Staging  Multi-stage Programs In Context - Matthew Pickering, Nicolas Wu, Jamie Willis Selective Staged Parser Combinators - Jamie Willis, Nicolas Wu, Matthew Pickering (optimising parser combinators with staging)   Codensity transformations  Csongor used the codensity transform in his generic deriving paper   Tagless final style (optimises mtl style?</description>
    </item>
    
    <item>
      <title>Effects for Less</title>
      <link>https://probabilistic-effects.github.io/research/effects-for-less/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:31 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/effects-for-less/</guid>
      <description>Table of Contents  Summary Thoughts Benchmarking  Summary of Alexis King - focusing on benchmarks
Summary  Real world benchmarks make it difficult to isolate costs Microbenchmarks often seen as synthetic Microbenchmarks need to make sure you&amp;rsquo;re measuring the right thing Might not have broad scope. Effects systems make real world programs hard to benchmark Effects systems tend to have small operations that do not take a significant amount of time Splitting in modules slows stuff down Compiler optimisations lead to cross module slowdowns Free monad libraries, by constructing trees, obscures the program structure to the optimiser preventing inlining.</description>
    </item>
    
    <item>
      <title>Literature Review</title>
      <link>https://probabilistic-effects.github.io/research/literature-review/</link>
      <pubDate>Fri, 13 Nov 2020 14:05:31 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/literature-review/</guid>
      <description>‣ Papers Probabilistic Programming
 Practical Probabilistic Programming with Monads - Ścibior, Adam, Zoubin Ghahramani, and Andrew D. Gordon. Proceedings of the 2015 ACM SIGPLAN Symposium on Haskell. 2015. Functional Programming for Modular Bayesian Inference - Ścibior, Adam, Ohad Kammar, and Zoubin Ghahramani. Proceedings of the ACM on Programming Languages 2. ICFP (2018): 1-29. Formally Justified and Modular Bayesian Inference for Probabilistic Programs - Ścibior, Adam Michał. Diss. University of Cambridge, 2019.</description>
    </item>
    
    <item>
      <title>Inference Transformers</title>
      <link>https://probabilistic-effects.github.io/monad-bayes/inference-transformers/</link>
      <pubDate>Fri, 13 Nov 2020 14:04:56 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/monad-bayes/inference-transformers/</guid>
      <description>Inference Representation Type Classes type R = Double class Monad m =&amp;gt; MonadSample m where random :: m R bernoulli :: R -&amp;gt; m Bool bernoulli p = fmap ( &amp;lt; p ) random -- and other default distributions : -- normal , gamma , beta , geometric , -- poisson , dirichlet class Monad m ⇒ MonadCond m where score :: Log R -&amp;gt; m () class ( MonadSample m , MonadCond m ) =&amp;gt; MonadInfer m  Sampler This inference transformer is a sampler that draws concrete values for random variables from the prior.</description>
    </item>
    
    <item>
      <title>Implementing HMM Simulation and Inference (using PMMH)</title>
      <link>https://probabilistic-effects.github.io/monad-bayes/pmmh-hmm/</link>
      <pubDate>Fri, 13 Nov 2020 14:04:50 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/monad-bayes/pmmh-hmm/</guid>
      <description>Simulating Data We aim to model a HMM and use it to generate data by simulating a sample path.
First, for simplicity we consider our latent states xi to be integers, and the corresponding observed states yi to also be integers.
data ObservedState = Obs { obs :: Int } deriving Show data LatentState = Lat { lat :: Int } deriving Show We then choose the parameters of the HMM (i.</description>
    </item>
    
    <item>
      <title>How Conditioning and Scoring Works</title>
      <link>https://probabilistic-effects.github.io/monad-bayes/conditioning-scoring/</link>
      <pubDate>Fri, 13 Nov 2020 14:04:44 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/monad-bayes/conditioning-scoring/</guid>
      <description>A sample path is the course of a program as it executes, hence being the monadic context that the code is executing in. During this path, a new thread created for every random decision. It can be thought of as an execution trace. In probabilistic programming, each sample path is associated with a probability of how likely that execution trace is to happen. This probability is the joint probability of a bunch of random decisions made during the execution of the program.</description>
    </item>
    
    <item>
      <title>Benchmark Log</title>
      <link>https://probabilistic-effects.github.io/benchmarking/benchmark-log/</link>
      <pubDate>Fri, 13 Nov 2020 14:02:28 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/benchmarking/benchmark-log/</guid>
      <description>PMMH Inference on HMM This details the benchmarks for a program using monad-bayes to run PMMH inference on a HMM, whilst tactically adding various {-# INLINE #-} pragmas to functions of the monad-bayes library in response to analysing the Haskell core generated. Each benchmark is the average over 4 iterations.
Source Program
main = defaultMain [ bgroup &amp;#34;runPmmh&amp;#34; [ bench &amp;#34;(100, 100, 100)&amp;#34; $ whnfIO $ runPmmh (100, 100, 100) ] ] runPmmh :: (Int, Int, Int) -&amp;gt; IO () runPmmh (n_mhsteps, n_timesteps, n_particles) = do particleWeightings &amp;lt;- inferModel n_mhsteps n_timesteps n_particles print particleWeightings  Original Code   Inline pragma added to pmmh function   Inline pragma added to pushEvidence function   Inline pragma added to hoist function   Inline pragma added to mhTrans functions   Inline pragma added to Traced.</description>
    </item>
    
    <item>
      <title>How to Benchmark and Profile</title>
      <link>https://probabilistic-effects.github.io/benchmarking/benchmarking-profiling/</link>
      <pubDate>Fri, 13 Nov 2020 14:02:28 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/benchmarking/benchmarking-profiling/</guid>
      <description>Benchmarking With Criterion &amp;amp; Stack   The benchmark program we intend to profile needs to have a function which takes one argument (influencing the computational effort of executing the program) - this is the function we directly call for profiling.
This should be under the test directory, e.g. test/BenchmarkProgram.hs which contains a function:
testPmmh :: Int -&amp;gt; IO () testPmmh nsteps = do observedStates &amp;lt;- generateData initLatentState initParams nsteps print observedStates   The program that calls the profiling functions should ideally be test/Spec.</description>
    </item>
    
    <item>
      <title>Relevant Components of Monad Bayes for Profiling</title>
      <link>https://probabilistic-effects.github.io/benchmarking/monad-bayes-components/</link>
      <pubDate>Fri, 13 Nov 2020 14:01:54 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/benchmarking/monad-bayes-components/</guid>
      <description>What constitutes a good benchmark - Concrete components/transformers of interest:
These are plausible components for benchmarking the performance of individual concrete transformers.
  SamplerIO
-- | An &amp;#39;IO&amp;#39; based random sampler using the MWC-Random package. newtype SamplerIO a = SamplerIO (ReaderT GenIO IO a) deriving (Functor, Applicative, Monad, MonadIO)   SamplerST
-- | An &amp;#39;ST&amp;#39; based random sampler using the MWC-Random package. newtype SamplerST a = SamplerST (forall s.</description>
    </item>
    
    <item>
      <title>Staging</title>
      <link>https://probabilistic-effects.github.io/background/staging/</link>
      <pubDate>Fri, 13 Nov 2020 13:59:01 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/staging/</guid>
      <description>Staging and metaprogramming are the same; Template Haskell is a metaprogramming library for Haskell. We have different stages of computation, so staging a program is making it so that it compiles different parts of the program at different stages to be used by other parts of a program at a later stage.
Building blocks of Template Haskell The core mechanisms of Template Haskell are:
 Evaluating Haskell meta-programs at compile-time and splicing in the generated object programs as regular Haskell code Representing Template Haskell object programs as algebraic data types The quotation monad Q  • Writing a meta-program</description>
    </item>
    
    <item>
      <title>SMC and PMMH</title>
      <link>https://probabilistic-effects.github.io/background/smc-pmmh/</link>
      <pubDate>Fri, 13 Nov 2020 13:58:54 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/smc-pmmh/</guid>
      <description>Particle Filter Sequential Monte Carlo (SMC) methods, also known as Particle Filters, are a set of simulation-based methods (to artificially generate data to test a hypothesis) which provide an approach to computing the posterior distribution. The objective is to compute the posterior distributions of the states of some hidden Markov Model process, where the system consists of both hidden and observable variables.
The observable variables (observation process) are related to the hidden variables (state process) by some functional form that is known.</description>
    </item>
    
    <item>
      <title>Handrolling Monad Transformer Stacks</title>
      <link>https://probabilistic-effects.github.io/background/handrolling/</link>
      <pubDate>Fri, 13 Nov 2020 13:58:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/handrolling/</guid>
      <description>Unrolling MTL stacks Stacked monad transformers do not inline well and the MTL library often requires an optimisation pass.
Unrolling means to flatten a stack of transformers into a single hand-unrolled monad.
For example, consider the following MTL monad stack.
-- RWS monad: A monad containing an environment of type r, output of type w, and updatable state of type s. type RWS r w s = RWST r w s Identity deriving (MonadState s, MonadWriter w, Monad) newtype DRM a = DRM { unDRM :: ErrorT Finish (RWS () DNA RNA) a } deriving (MonadState DNA, MonadWriter RNA, MonadError Finish, Monad) -- | Inductive case: This tells us that as we know there is a MonadState and MonadWriter instance -- somewhere in the stack (i.</description>
    </item>
    
    <item>
      <title>MTL</title>
      <link>https://probabilistic-effects.github.io/background/mtl/</link>
      <pubDate>Fri, 13 Nov 2020 13:58:35 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/mtl/</guid>
      <description>Ordinary monad transformers Using ordinary monad transformers, we would have to construct a transformer stack like the following example:
type Environment = [(String, Int)] type Counter = Int newtype M a = M (ReaderT Environment (StateT Counter IO) a) deriving (Functor, Applicative, Monad) -- This inverts into something like IO (State Counter (Reader Environment a)) In order to access the environment, we can use the ask operation from Control.Monad.Trans.Reader, but we have to wrap this up in the M newtype.</description>
    </item>
    
    <item>
      <title>MCMC and MH</title>
      <link>https://probabilistic-effects.github.io/background/mcmc-mh/</link>
      <pubDate>Fri, 13 Nov 2020 13:58:28 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/mcmc-mh/</guid>
      <description>Monte Carlo Monte Carlo methods, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results.
These methods vary, but tend to follow a particular pattern:
 Define a domain of possible inputs Generate inputs randomly from a probability distribution over the domain Perform a deterministic computation on the inputs Aggregate the results   Markov Chain Monte Carlo (MCMC) Markov Chain Monte Carlo (MCMC) methods are from a class of techniques known as approximate inference which are a range of algorithms for computing posteriors when the likelihood is intractable.</description>
    </item>
    
    <item>
      <title>Markov Chains</title>
      <link>https://probabilistic-effects.github.io/background/markov-chain/</link>
      <pubDate>Fri, 13 Nov 2020 13:58:20 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/markov-chain/</guid>
      <description>Markov Chain A Markov Chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.
A Markov chain is a model that tells us about the probabilities of sequences of random variables, states, each of which can take on values from some set.
Formally, a Markov chain is specified by the following components:</description>
    </item>
    
    <item>
      <title>Hidden Markov Model</title>
      <link>https://probabilistic-effects.github.io/background/hidden-markov-model/</link>
      <pubDate>Fri, 13 Nov 2020 13:58:10 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/hidden-markov-model/</guid>
      <description>HMM A Markov chain is useful when we need to compute a probability for a sequence of observable events. In many cases, the events we are interested in are hidden - meaning we don&amp;rsquo;t observe them directly.
HMM allows us to talk about both observed events and hidden events that we think of as causal factors in our probabilistic model.
A HMM is specified by the following components:
  A set of N states</description>
    </item>
    
    <item>
      <title>Delimited Continuations</title>
      <link>https://probabilistic-effects.github.io/background/delimited-continuations/</link>
      <pubDate>Fri, 13 Nov 2020 13:57:22 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/delimited-continuations/</guid>
      <description>Delimited Continuations A limiting factor for effect system performance is the need to implement delimited continuations outside of the runtime. Accordingly, this proposal presents a design for native delimited continuation primitive operations that can be used to efficiently capture the RTS (runtime system) stack. A guiding principle of the design is to be minimal. Rather than burden GHC with the full complexity of designing and implementing algebraic effects, this proposal provides a path for users to experiment with designs as ordinary Haskell libraries without sacrificing performance.</description>
    </item>
    
    <item>
      <title>Case Study: Optimising Parsley</title>
      <link>https://probabilistic-effects.github.io/research/parsley-case-study/</link>
      <pubDate>Fri, 13 Nov 2020 13:49:05 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/parsley-case-study/</guid>
      <description>The best way to understand why a profiling report outputs certain performance metrics (for Haskell) is to dive into the actual core itself, which is what the surface-level Haskell code compiles down into.
Usually, if one is confused about something in the core, it is best to compare it with the original program.
regTest :: Parser Int regTest = newRegister_ (code 7) (\r -&amp;gt; modify_ r makeQ (succ @Int) [||succ @Int||]) *&amp;gt; (let g = get r in g *&amp;gt; g)) This makes a new register, which in this context would be an STRef, containing 7; it then modifies it with +1, and afterwards it gets the value out twice, and returns it the second time.</description>
    </item>
    
    <item>
      <title>Haskell Core</title>
      <link>https://probabilistic-effects.github.io/background/haskell-core/</link>
      <pubDate>Fri, 13 Nov 2020 13:49:05 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/haskell-core/</guid>
      <description>• Core Language
The definition of the core language of GHC is given below - all source programs are compiled into this core language. All optimisation passes are in terms of this core language rather than the source programs.
data Expr b = Var Id | Lit Literal | App (Expr b) (Arg b) | Lam b (Expr b) | Let (Bind b) (Expr b) | Case (Expr b) b Type [Alt b] | Cast (Expr b) Coercion | Tick (Tickish Id) (Expr b) | Type Type | Coercion Coercion type Arg b = Expr b type Alt b = (AltCon, [b], Expr b) data AltCon = DataAlt DataCon | LitAlt Literal | DEFAULT data Bind b = NonRec b (Expr b) | Rec [(b, (Expr b))] • Basic Optimisations on Core</description>
    </item>
    
    <item>
      <title>Inlining</title>
      <link>https://probabilistic-effects.github.io/background/inlining/</link>
      <pubDate>Fri, 13 Nov 2020 13:49:05 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/inlining/</guid>
      <description>The most critical optimisation for an automatic optimiser is inlining. Inlining is the enabling optimisation which replaces a function name by the definition of that function. After a function definition has been inlined, new optimisation opportunities are now evident to the optimiser such as the β-reduction and know-case elimination optimisations.
The difficulty with inlining is that on its own it is not a beneficial code transformation. Inlining a function which does not unlock any further optimisation possibilities is wasted work which increases code size.</description>
    </item>
    
    <item>
      <title>Specialisation</title>
      <link>https://probabilistic-effects.github.io/background/specialisation/</link>
      <pubDate>Fri, 13 Nov 2020 13:49:05 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/specialisation/</guid>
      <description>Type class constraints in Haskell are implemented via dictionary passing. A function accepting a type class constraint is passed a record which provides evidence for the constraint. Therefore despite the fact that all instances have been statically resolved before runtime, the dictionaries are still passed to functions which can incur significant overhead.
Since type classes are ubiquitous, getting rid of this overhead is critical for any high-performance Haskell programs. Therefore one of the most important optimisations in the compiler is specialisation which rewrites functions to remove the overhead of passing a statically known dictionary.</description>
    </item>
    
    <item>
      <title>Continuations</title>
      <link>https://probabilistic-effects.github.io/background/continuations/</link>
      <pubDate>Fri, 13 Nov 2020 13:40:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/background/continuations/</guid>
      <description>What are continuations? Continuations represent the future of a computation, as a function from an intermediate result to the final result. Direct-style functions are computations which return their result directly, with general type a -&amp;gt; b.
The direct-style factorial fac takes a single argument.
fac :: Integral a =&amp;gt; a -&amp;gt; a fac 0 = 1 fac n = n * fac (n - 1) Continuation-passing-style functions are suspended computations with general type a -&amp;gt; (b -&amp;gt; r) -&amp;gt; r, which represent direct-style functions with type a -&amp;gt; b.</description>
    </item>
    
    <item>
      <title>Optimising Core</title>
      <link>https://probabilistic-effects.github.io/research/optimising-core/</link>
      <pubDate>Fri, 13 Nov 2020 13:40:41 +0000</pubDate>
      
      <guid>https://probabilistic-effects.github.io/research/optimising-core/</guid>
      <description>These are some organised notes on optimising core, summarised from other pages.
1. Dumping core &amp;amp; enabling optimisations   To inspect the core (in a coherent manner), we can add the following to either our package.yaml file (when using stack):
ghc-options: - dump-core dependencies: - -fplugin=DumpCore or our .cabal file (when using cabal):
build-depends: dump-core ghc-options: -fplugin-DumpCore When we build our program (stack build or ghc), this creates a folder called dump-core containing html files.</description>
    </item>
    
  </channel>
</rss>
